{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edf5b5ac-2cc1-4a6d-accb-bab22b417a5f",
   "metadata": {},
   "source": [
    "# Parametric study on the dimension of the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c114b7b2-7498-44f8-8d9f-81fbb090a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "## import functions\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src import Train_test_sets_maker\n",
    "from src import MinMaxNormalisation\n",
    "from src import Visualize\n",
    "from src import MIMII_AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d7c53ac-4f53-42f4-9529-5c273f327496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(wav_name,channel=4):\n",
    "    try:\n",
    "        multi_channel_data, sr = sf.read(wav_name)\n",
    "        if multi_channel_data.ndim <= 1:\n",
    "            # ADD HERE A CONDITION TO READ MULTICHANNEL LENGTH AND REMOVE IF TOO SHORT\n",
    "            return sr, multi_channel_data\n",
    "        return sr, np.array(multi_channel_data)[:,channel]\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "def PSD_DF_Maker(user_path,data_path):\n",
    "    your_path = user_path+data_path\n",
    "    files = os.listdir(your_path)\n",
    "    \n",
    "    PSD_list = [] \n",
    "    \n",
    "    for index,file in enumerate(files):\n",
    "        if os.path.isfile(os.path.join(your_path,file)):\n",
    "\n",
    "            fs, audio = import_data(os.path.join(your_path,file))\n",
    "            f_vec, PSD = signal.welch(audio, fs, nperseg=1024)\n",
    "            PSD = PSD[f_vec < 3000]\n",
    "\n",
    "            PSD_list.append(PSD)\n",
    "    return pd.DataFrame(PSD_list)\n",
    "\n",
    "def lossCalcMSE(model,data):\n",
    "    reconstructions = model(tf.cast(data,float))\n",
    "    return tf.keras.losses.mse(reconstructions,data)\n",
    "\n",
    "#lossValues = lossCalcMSE(autoencoder, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ebb016f7-2bb1-46d8-a316-7d43ee361277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train & test sets created !\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 179ms/step - loss: 0.0028 - val_loss: 0.0203\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0027 - val_loss: 0.0200\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0026 - val_loss: 0.0197\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0025 - val_loss: 0.0193\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0023 - val_loss: 0.0189\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0022 - val_loss: 0.0184\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0020 - val_loss: 0.0178\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0019 - val_loss: 0.0172\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0164\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0015 - val_loss: 0.0156\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0014 - val_loss: 0.0146\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0012 - val_loss: 0.0136\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 9.7773e-04 - val_loss: 0.0125\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 8.0370e-04 - val_loss: 0.0114\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 6.5253e-04 - val_loss: 0.0103\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 5.2341e-04 - val_loss: 0.0093\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 4.1944e-04 - val_loss: 0.0085\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 3.3674e-04 - val_loss: 0.0079\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 2.7345e-04 - val_loss: 0.0074\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.2723e-04 - val_loss: 0.0070\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.9553e-04 - val_loss: 0.0067\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.7249e-04 - val_loss: 0.0064\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.5571e-04 - val_loss: 0.0061\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.4463e-04 - val_loss: 0.0059\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.3854e-04 - val_loss: 0.0058\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.3595e-04 - val_loss: 0.0058\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.3547e-04 - val_loss: 0.0058\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.3495e-04 - val_loss: 0.0058\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.3337e-04 - val_loss: 0.0058\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.3105e-04 - val_loss: 0.0057\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.2823e-04 - val_loss: 0.0057\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2522e-04 - val_loss: 0.0057\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2206e-04 - val_loss: 0.0056\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1928e-04 - val_loss: 0.0055\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1718e-04 - val_loss: 0.0054\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.1552e-04 - val_loss: 0.0053\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1435e-04 - val_loss: 0.0052\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1332e-04 - val_loss: 0.0051\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1253e-04 - val_loss: 0.0050\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1204e-04 - val_loss: 0.0049\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1165e-04 - val_loss: 0.0048\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1120e-04 - val_loss: 0.0047\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1080e-04 - val_loss: 0.0046\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1013e-04 - val_loss: 0.0046\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0938e-04 - val_loss: 0.0045\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.0868e-04 - val_loss: 0.0045\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0798e-04 - val_loss: 0.0044\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.0739e-04 - val_loss: 0.0043\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0692e-04 - val_loss: 0.0043\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0649e-04 - val_loss: 0.0042\n"
     ]
    }
   ],
   "source": [
    "### Path files\n",
    "names = ['fan']\n",
    "stati = ['normal', 'abnormal']\n",
    "SNR = ['+6dB', '-6dB']\n",
    "\n",
    "folder = '/MIMII/RawData/' + SNR[0] + '/' # fan/id_00/abnormal'\n",
    "user_path = 'C:/Users/carbo/Documents/'\n",
    "writer_path = 'C:/Users/carbo/Documents/MIMII/Data/' + SNR[0] +'/PSD/'\n",
    "\n",
    "### Parameters\n",
    "#IDs = ['id_00','id_02', 'id_04', 'id_06']\n",
    "\n",
    "IDs = ['id_00']\n",
    "\n",
    "AUCs = []\n",
    "\n",
    "latent_space = []\n",
    "\n",
    "for ID in IDs:\n",
    "\n",
    "    # Get data\n",
    "    #ID = IDs[2]\n",
    "    status = stati[0] # normal\n",
    "    name = names[0]\n",
    "    data_path = folder + name + '/' + ID + '/' + status\n",
    "    df_PSD_normal = PSD_DF_Maker(user_path, data_path)\n",
    "\n",
    "    status = stati[1] # abnormal\n",
    "    data_path = folder + name + '/' + ID + '/' + status\n",
    "    df_PSD_abnormal = PSD_DF_Maker(user_path, data_path)\n",
    "\n",
    "    # Create datasets for training/evaluation\n",
    "    train_set, test_set, test_labels = Train_test_sets_maker.fun(df_PSD_normal,df_PSD_abnormal)\n",
    "    # Normalize\n",
    "    MIN,MAX = MinMaxNormalisation.getMinMax(train_set)\n",
    "    train_set = MinMaxNormalisation.fun(train_set,MIN,MAX)\n",
    "    test_set = MinMaxNormalisation.fun(test_set,MIN,MAX)\n",
    "\n",
    "\n",
    "    # Train algorithm\n",
    "    autoencoder = MIMII_AE.fun(train_set.shape[1])\n",
    "    history = autoencoder.fit(train_set, train_set, \n",
    "                              epochs=50, \n",
    "                              batch_size=512,\n",
    "                              validation_data=(test_set,test_set),\n",
    "                              validation_split = 0.1,\n",
    "                              verbose = 1,\n",
    "                              shuffle=True\n",
    "                             )\n",
    "    \n",
    "    lossValues = lossCalcMSE(autoencoder, test_set)\n",
    "    AUCs.append(metrics.roc_auc_score(~test_labels, lossValues))      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05917343-f70e-4d93-b66b-3ba229d8ccac",
   "metadata": {},
   "source": [
    "## Latent space parametrisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "14af4621-4775-4323-b781-b4e71b36ac10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007807</td>\n",
       "      <td>0.030539</td>\n",
       "      <td>0.034418</td>\n",
       "      <td>0.083895</td>\n",
       "      <td>0.497701</td>\n",
       "      <td>0.304752</td>\n",
       "      <td>0.020914</td>\n",
       "      <td>0.027205</td>\n",
       "      <td>0.130414</td>\n",
       "      <td>0.180463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.000373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008302</td>\n",
       "      <td>0.037215</td>\n",
       "      <td>0.036163</td>\n",
       "      <td>0.082343</td>\n",
       "      <td>0.464568</td>\n",
       "      <td>0.289044</td>\n",
       "      <td>0.025346</td>\n",
       "      <td>0.023648</td>\n",
       "      <td>0.101207</td>\n",
       "      <td>0.146460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015148</td>\n",
       "      <td>0.070005</td>\n",
       "      <td>0.069551</td>\n",
       "      <td>0.124495</td>\n",
       "      <td>0.597622</td>\n",
       "      <td>0.345013</td>\n",
       "      <td>0.034348</td>\n",
       "      <td>0.038554</td>\n",
       "      <td>0.128566</td>\n",
       "      <td>0.163284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.000562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013738</td>\n",
       "      <td>0.070504</td>\n",
       "      <td>0.062392</td>\n",
       "      <td>0.069128</td>\n",
       "      <td>0.281326</td>\n",
       "      <td>0.160750</td>\n",
       "      <td>0.023840</td>\n",
       "      <td>0.061850</td>\n",
       "      <td>0.182800</td>\n",
       "      <td>0.172611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.001096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.015891</td>\n",
       "      <td>0.083021</td>\n",
       "      <td>0.088098</td>\n",
       "      <td>0.104561</td>\n",
       "      <td>0.389981</td>\n",
       "      <td>0.217808</td>\n",
       "      <td>0.039632</td>\n",
       "      <td>0.047825</td>\n",
       "      <td>0.155283</td>\n",
       "      <td>0.188809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.000448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.007807  0.030539  0.034418  0.083895  0.497701  0.304752  0.020914   \n",
       "1  0.008302  0.037215  0.036163  0.082343  0.464568  0.289044  0.025346   \n",
       "2  0.015148  0.070005  0.069551  0.124495  0.597622  0.345013  0.034348   \n",
       "3  0.013738  0.070504  0.062392  0.069128  0.281326  0.160750  0.023840   \n",
       "8  0.015891  0.083021  0.088098  0.104561  0.389981  0.217808  0.039632   \n",
       "\n",
       "        7         8         9    ...       182       183       184       185  \\\n",
       "0  0.027205  0.130414  0.180463  ...  0.000333  0.000333  0.000365  0.000366   \n",
       "1  0.023648  0.101207  0.146460  ...  0.000353  0.000290  0.000251  0.000296   \n",
       "2  0.038554  0.128566  0.163284  ...  0.000568  0.000537  0.000480  0.000435   \n",
       "3  0.061850  0.182800  0.172611  ...  0.000660  0.000708  0.000781  0.000830   \n",
       "8  0.047825  0.155283  0.188809  ...  0.000511  0.000501  0.000449  0.000471   \n",
       "\n",
       "        186       187       188       189       190       191  \n",
       "0  0.000440  0.000360  0.000313  0.000320  0.000336  0.000373  \n",
       "1  0.000288  0.000343  0.000312  0.000337  0.000352  0.000348  \n",
       "2  0.000457  0.000405  0.000507  0.000664  0.000654  0.000562  \n",
       "3  0.000896  0.001027  0.001334  0.001434  0.001250  0.001096  \n",
       "8  0.000360  0.000347  0.000383  0.000442  0.000391  0.000448  \n",
       "\n",
       "[5 rows x 192 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6748e959-4a02-4deb-87c5-f0087ac71c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.052693\n",
       "1      0.303920\n",
       "2      0.242283\n",
       "3      0.114076\n",
       "4      0.457656\n",
       "         ...   \n",
       "187    0.000300\n",
       "188    0.000325\n",
       "189    0.000276\n",
       "190    0.000308\n",
       "191    0.000286\n",
       "Name: 353, Length: 192, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "65842788-cb12-4358-ae66-a64f3be3eeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_test_set = tf.cast(test_set,float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2c92abb4-8e21-49b7-b13a-e61d75697380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(814, 192), dtype=float32, numpy=\n",
       "array([[ 5.26929460e-02,  3.03919822e-01,  2.42283031e-01, ...,\n",
       "         2.76168867e-04,  3.07867624e-04,  2.85802031e-04],\n",
       "       [ 1.72184706e-02,  8.14054832e-02,  7.14851767e-02, ...,\n",
       "         2.35127212e-04,  3.01935623e-04,  3.31047195e-04],\n",
       "       [ 1.99281219e-02,  9.66267586e-02,  9.23989788e-02, ...,\n",
       "         4.10531793e-04,  4.82653530e-04,  3.36285913e-04],\n",
       "       ...,\n",
       "       [ 3.00001334e-02,  1.24714255e-01,  9.30833742e-02, ...,\n",
       "        -2.84275186e-04, -2.77282757e-04, -2.67536321e-04],\n",
       "       [ 1.89008527e-02,  9.48643237e-02,  8.13147426e-02, ...,\n",
       "         2.10503989e-04,  1.51107582e-04,  1.45503378e-04],\n",
       "       [ 3.37217227e-02,  1.40131533e-01,  1.32102847e-01, ...,\n",
       "         1.60857293e-04,  1.29621010e-04,  1.77739377e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4f7bf6d3-52c7-46d8-8cbd-c572c6e4a8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = autoencoder.encoder(tf_test_set,192).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "00b9e2a6-804a-4fb8-a82d-16a18a688f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08315315, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.5140048 , 0.21146734, 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "736883c4-1d8e-41d2-9e52-687ec0ce45cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07081422, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.6009894 , 0.21250372, 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data[1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9867af0b-e6d2-43a2-85ce-9bace79bbdba",
   "metadata": {},
   "source": [
    "## Latent space visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bde894-04be-4d6d-aa04-04ab47726368",
   "metadata": {},
   "source": [
    "It seems only 3 features actually contribute to the representation of the data in the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0b88bb12-93d5-4198-b906-c307ae870f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_name = ['1','2','3','4','5','6','7','8']\n",
    "for data in encoded_data:\n",
    "    plt.bar(feature_name, data, alpha=0.1)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7df442-d046-4333-8141-9e0ac50d4fdf",
   "metadata": {},
   "source": [
    "## Relearning using only 3 features in latent space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "32485530-2950-45b2-b68b-189e4307b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, losses\n",
    "\n",
    "class AnomalyDetector(Model):\n",
    "    \n",
    "  def __init__(self,InputSize):\n",
    "    super(AnomalyDetector, self).__init__()\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(3, activation=\"relu\"),\n",
    "    ])\n",
    "    \n",
    "\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(InputSize, activation=\"linear\")])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "def fun(InputSize, loss_fun = \"mse\"):\n",
    "    \n",
    "    AE =  AnomalyDetector(InputSize)\n",
    "    AE.compile(loss=loss_fun,\n",
    "               optimizer='adam'\n",
    "              )\n",
    "    return AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3ae6e963-3a5c-4223-a4f8-c5c768edd422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train & test sets created !\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 153ms/step - loss: 0.0028 - val_loss: 0.0204\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0027 - val_loss: 0.0202\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0026 - val_loss: 0.0200\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0025 - val_loss: 0.0197\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0024 - val_loss: 0.0194\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0023 - val_loss: 0.0191\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0021 - val_loss: 0.0187\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0020 - val_loss: 0.0182\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0019 - val_loss: 0.0176\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0017 - val_loss: 0.0169\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0015 - val_loss: 0.0161\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0013 - val_loss: 0.0152\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0012 - val_loss: 0.0142\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 9.5715e-04 - val_loss: 0.0131\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 7.7179e-04 - val_loss: 0.0119\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 6.0548e-04 - val_loss: 0.0107\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 4.6862e-04 - val_loss: 0.0096\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 3.5951e-04 - val_loss: 0.0086\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.8091e-04 - val_loss: 0.0079\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.2553e-04 - val_loss: 0.0075\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.8959e-04 - val_loss: 0.0072\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7087e-04 - val_loss: 0.0071\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.6418e-04 - val_loss: 0.0071\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6265e-04 - val_loss: 0.0070\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.5990e-04 - val_loss: 0.0069\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.5375e-04 - val_loss: 0.0068\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.4634e-04 - val_loss: 0.0067\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.3945e-04 - val_loss: 0.0067\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.3381e-04 - val_loss: 0.0067\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2948e-04 - val_loss: 0.0067\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2632e-04 - val_loss: 0.0067\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2406e-04 - val_loss: 0.0067\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.2263e-04 - val_loss: 0.0067\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2143e-04 - val_loss: 0.0067\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2007e-04 - val_loss: 0.0066\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1868e-04 - val_loss: 0.0065\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1722e-04 - val_loss: 0.0064\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1567e-04 - val_loss: 0.0063\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1428e-04 - val_loss: 0.0062\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.1303e-04 - val_loss: 0.0062\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.1216e-04 - val_loss: 0.0061\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1142e-04 - val_loss: 0.0060\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1068e-04 - val_loss: 0.0059\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0986e-04 - val_loss: 0.0058\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0910e-04 - val_loss: 0.0056\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0837e-04 - val_loss: 0.0055\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0764e-04 - val_loss: 0.0055\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0698e-04 - val_loss: 0.0054\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0646e-04 - val_loss: 0.0053\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0575e-04 - val_loss: 0.0052\n"
     ]
    }
   ],
   "source": [
    "### Path files\n",
    "names = ['fan']\n",
    "stati = ['normal', 'abnormal']\n",
    "SNR = ['+6dB', '-6dB']\n",
    "\n",
    "folder = '/MIMII/RawData/' + SNR[0] + '/' # fan/id_00/abnormal'\n",
    "user_path = 'C:/Users/carbo/Documents/'\n",
    "writer_path = 'C:/Users/carbo/Documents/MIMII/Data/' + SNR[0] +'/PSD/'\n",
    "\n",
    "### Parameters\n",
    "#IDs = ['id_00','id_02', 'id_04', 'id_06']\n",
    "\n",
    "IDs = ['id_00']\n",
    "\n",
    "AUCs = []\n",
    "\n",
    "latent_space = []\n",
    "\n",
    "for ID in IDs:\n",
    "\n",
    "    # Get data\n",
    "    #ID = IDs[2]\n",
    "    status = stati[0] # normal\n",
    "    name = names[0]\n",
    "    data_path = folder + name + '/' + ID + '/' + status\n",
    "    df_PSD_normal = PSD_DF_Maker(user_path, data_path)\n",
    "\n",
    "    status = stati[1] # abnormal\n",
    "    data_path = folder + name + '/' + ID + '/' + status\n",
    "    df_PSD_abnormal = PSD_DF_Maker(user_path, data_path)\n",
    "\n",
    "    # Create datasets for training/evaluation\n",
    "    train_set, test_set, test_labels = Train_test_sets_maker.fun(df_PSD_normal,df_PSD_abnormal)\n",
    "    # Normalize\n",
    "    MIN,MAX = MinMaxNormalisation.getMinMax(train_set)\n",
    "    train_set = MinMaxNormalisation.fun(train_set,MIN,MAX)\n",
    "    test_set = MinMaxNormalisation.fun(test_set,MIN,MAX)\n",
    "\n",
    "\n",
    "    # Train algorithm\n",
    "    autoencoder = fun(train_set.shape[1])\n",
    "    history = autoencoder.fit(train_set, train_set, \n",
    "                              epochs=50, \n",
    "                              batch_size=512,\n",
    "                              validation_data=(test_set,test_set),\n",
    "                              validation_split = 0.1,\n",
    "                              verbose = 1,\n",
    "                              shuffle=True\n",
    "                             )\n",
    "    \n",
    "    lossValues = lossCalcMSE(autoencoder, test_set)\n",
    "    AUCs.append(metrics.roc_auc_score(~test_labels, lossValues))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0004a8a2-7861-4afa-ba04-8789ba028661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9452577437835423]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b59ca5a3-464a-41c5-9e5a-94a8d2957911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf_test_set = tf.cast(test_set,float)\n",
    "encoded_data = autoencoder.encoder(tf_test_set,192).numpy()\n",
    "feature_name = ['1','2','3']\n",
    "for data in encoded_data:\n",
    "    plt.bar(feature_name, data, alpha=0.1)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6894f430-a31f-45da-8850-c13a7c577eb7",
   "metadata": {},
   "source": [
    "Only 1 feature in the latent space is enough ? Let's see that !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "71b2c7b3-fd06-4697-b8da-0f2b8e7c991f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train & test sets created !\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 159ms/step - loss: 0.0035 - val_loss: 0.0252\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0034 - val_loss: 0.0251\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0033 - val_loss: 0.0249\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0032 - val_loss: 0.0247\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0031 - val_loss: 0.0245\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0030 - val_loss: 0.0243\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0029 - val_loss: 0.0240\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0027 - val_loss: 0.0238\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0026 - val_loss: 0.0234\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0025 - val_loss: 0.0231\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0023 - val_loss: 0.0227\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0021 - val_loss: 0.0222\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0020 - val_loss: 0.0216\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0018 - val_loss: 0.0209\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0015 - val_loss: 0.0202\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0013 - val_loss: 0.0193\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0011 - val_loss: 0.0183\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 8.8442e-04 - val_loss: 0.0171\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 6.8777e-04 - val_loss: 0.0159\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 5.2917e-04 - val_loss: 0.0147\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 4.1513e-04 - val_loss: 0.0135\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 3.4666e-04 - val_loss: 0.0126\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 3.0295e-04 - val_loss: 0.0121\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.6093e-04 - val_loss: 0.0120\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 2.2349e-04 - val_loss: 0.0121\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 2.0158e-04 - val_loss: 0.0123\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.9438e-04 - val_loss: 0.0125\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.9356e-04 - val_loss: 0.0126\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.9447e-04 - val_loss: 0.0127\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.9360e-04 - val_loss: 0.0126\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.9047e-04 - val_loss: 0.0124\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.8708e-04 - val_loss: 0.0122\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.8394e-04 - val_loss: 0.0121\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.8052e-04 - val_loss: 0.0120\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7683e-04 - val_loss: 0.0119\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7310e-04 - val_loss: 0.0119\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6985e-04 - val_loss: 0.0119\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.6711e-04 - val_loss: 0.0120\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.6557e-04 - val_loss: 0.0120\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.6479e-04 - val_loss: 0.0120\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.6432e-04 - val_loss: 0.0120\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.6371e-04 - val_loss: 0.0119\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6321e-04 - val_loss: 0.0118\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.6261e-04 - val_loss: 0.0117\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.6185e-04 - val_loss: 0.0116\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.6113e-04 - val_loss: 0.0115\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.6044e-04 - val_loss: 0.0114\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.5975e-04 - val_loss: 0.0113\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.5886e-04 - val_loss: 0.0112\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.5827e-04 - val_loss: 0.0112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, losses\n",
    "\n",
    "class AnomalyDetector(Model):\n",
    "    \n",
    "  def __init__(self,InputSize):\n",
    "    super(AnomalyDetector, self).__init__()\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(8, activation= \"relu\"),\n",
    "      layers.Dense(8, activation = \"relu\"),\n",
    "      layers.Dense(1, activation=\"relu\"),\n",
    "    ])\n",
    "    \n",
    "\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(8, activation= \"relu\"),\n",
    "      layers.Dense(8, activation= \"relu\"),\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(InputSize, activation=\"linear\")])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "def fun(InputSize, loss_fun = \"mse\"):\n",
    "    \n",
    "    AE =  AnomalyDetector(InputSize)\n",
    "    AE.compile(loss=loss_fun,\n",
    "               optimizer='adam'\n",
    "              )\n",
    "    return AE\n",
    "\n",
    "### Path files\n",
    "names = ['fan']\n",
    "stati = ['normal', 'abnormal']\n",
    "SNR = ['+6dB', '-6dB']\n",
    "\n",
    "folder = '/MIMII/RawData/' + SNR[0] + '/' # fan/id_00/abnormal'\n",
    "user_path = 'C:/Users/carbo/Documents/'\n",
    "writer_path = 'C:/Users/carbo/Documents/MIMII/Data/' + SNR[0] +'/PSD/'\n",
    "\n",
    "### Parameters\n",
    "#IDs = ['id_00','id_02', 'id_04', 'id_06']\n",
    "\n",
    "IDs = ['id_00']\n",
    "\n",
    "AUCs = []\n",
    "\n",
    "latent_space = []\n",
    "\n",
    "for ID in IDs:\n",
    "\n",
    "    # Get data\n",
    "    #ID = IDs[2]\n",
    "    status = stati[0] # normal\n",
    "    name = names[0]\n",
    "    data_path = folder + name + '/' + ID + '/' + status\n",
    "    df_PSD_normal = PSD_DF_Maker(user_path, data_path)\n",
    "\n",
    "    status = stati[1] # abnormal\n",
    "    data_path = folder + name + '/' + ID + '/' + status\n",
    "    df_PSD_abnormal = PSD_DF_Maker(user_path, data_path)\n",
    "\n",
    "    # Create datasets for training/evaluation\n",
    "    train_set, test_set, test_labels = Train_test_sets_maker.fun(df_PSD_normal,df_PSD_abnormal)\n",
    "    # Normalize\n",
    "    MIN,MAX = MinMaxNormalisation.getMinMax(train_set)\n",
    "    train_set = MinMaxNormalisation.fun(train_set,MIN,MAX)\n",
    "    test_set = MinMaxNormalisation.fun(test_set,MIN,MAX)\n",
    "\n",
    "\n",
    "    # Train algorithm\n",
    "    autoencoder = fun(train_set.shape[1])\n",
    "    history = autoencoder.fit(train_set, train_set, \n",
    "                              epochs=50, \n",
    "                              batch_size=512,\n",
    "                              validation_data=(test_set,test_set),\n",
    "                              validation_split = 0.1,\n",
    "                              verbose = 1,\n",
    "                              shuffle=True\n",
    "                             )\n",
    "    \n",
    "    lossValues = lossCalcMSE(autoencoder, test_set)\n",
    "    AUCs.append(metrics.roc_auc_score(~test_labels, lossValues))      \n",
    "    \n",
    "tf_test_set = tf.cast(test_set,float)\n",
    "encoded_data = autoencoder.encoder(tf_test_set,192).numpy()\n",
    "feature_name = ['1']\n",
    "for data in encoded_data:\n",
    "    plt.bar(feature_name, data, alpha=0.1)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7a1e7856-29dc-41fb-a2f8-13688e8edf85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9522363551847581]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUCs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f20eac-26ed-4100-a8fd-3c141e81689d",
   "metadata": {},
   "source": [
    "Let's see if the structure that has been shown here can be used to have 3 features that are non-zero and if that increases the AUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3c9a9996-4d20-4bcf-9b8d-cd6861f63dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train & test sets created !\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 147ms/step - loss: 0.0035 - val_loss: 0.0259\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0035 - val_loss: 0.0257\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0034 - val_loss: 0.0255\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0032 - val_loss: 0.0253\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0031 - val_loss: 0.0251\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0030 - val_loss: 0.0248\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0029 - val_loss: 0.0245\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0028 - val_loss: 0.0241\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0026 - val_loss: 0.0237\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0024 - val_loss: 0.0231\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0023 - val_loss: 0.0225\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0021 - val_loss: 0.0218\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0019 - val_loss: 0.0209\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0017 - val_loss: 0.0198\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0014 - val_loss: 0.0186\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0012 - val_loss: 0.0172\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 9.5360e-04 - val_loss: 0.0157\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 7.6057e-04 - val_loss: 0.0142\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 6.1799e-04 - val_loss: 0.0128\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 5.1781e-04 - val_loss: 0.0118\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 4.3262e-04 - val_loss: 0.0112\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.5063e-04 - val_loss: 0.0110\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.8064e-04 - val_loss: 0.0109\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.3406e-04 - val_loss: 0.0108\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.0887e-04 - val_loss: 0.0107\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.9653e-04 - val_loss: 0.0105\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.9009e-04 - val_loss: 0.0102\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.8739e-04 - val_loss: 0.0099\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.8581e-04 - val_loss: 0.0097\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.8468e-04 - val_loss: 0.0097\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.8260e-04 - val_loss: 0.0097\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.7914e-04 - val_loss: 0.0097\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.7463e-04 - val_loss: 0.0098\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7012e-04 - val_loss: 0.0098\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.6553e-04 - val_loss: 0.0098\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.6207e-04 - val_loss: 0.0097\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.5926e-04 - val_loss: 0.0097\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.5735e-04 - val_loss: 0.0097\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.5604e-04 - val_loss: 0.0096\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.5508e-04 - val_loss: 0.0096\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.5426e-04 - val_loss: 0.0096\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.5375e-04 - val_loss: 0.0096\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.5340e-04 - val_loss: 0.0095\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.5303e-04 - val_loss: 0.0093\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.5261e-04 - val_loss: 0.0092\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.5155e-04 - val_loss: 0.0091\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.5049e-04 - val_loss: 0.0090\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.4961e-04 - val_loss: 0.0089\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.4897e-04 - val_loss: 0.0087\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.4845e-04 - val_loss: 0.0086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, losses\n",
    "\n",
    "class AnomalyDetector(Model):\n",
    "    \n",
    "  def __init__(self,InputSize):\n",
    "    super(AnomalyDetector, self).__init__()\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(8, activation= \"relu\"),\n",
    "      layers.Dense(8, activation = \"relu\"),\n",
    "      layers.Dense(3, activation=\"relu\"),\n",
    "    ])\n",
    "    \n",
    "\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(8, activation= \"relu\"),\n",
    "      layers.Dense(8, activation= \"relu\"),\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(InputSize, activation=\"linear\")])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "def fun(InputSize, loss_fun = \"mse\"):\n",
    "    \n",
    "    AE =  AnomalyDetector(InputSize)\n",
    "    AE.compile(loss=loss_fun,\n",
    "               optimizer='adam'\n",
    "              )\n",
    "    return AE\n",
    "\n",
    "### Path files\n",
    "names = ['fan']\n",
    "stati = ['normal', 'abnormal']\n",
    "SNR = ['+6dB', '-6dB']\n",
    "\n",
    "folder = '/MIMII/RawData/' + SNR[0] + '/' # fan/id_00/abnormal'\n",
    "user_path = 'C:/Users/carbo/Documents/'\n",
    "writer_path = 'C:/Users/carbo/Documents/MIMII/Data/' + SNR[0] +'/PSD/'\n",
    "\n",
    "### Parameters\n",
    "#IDs = ['id_00','id_02', 'id_04', 'id_06']\n",
    "\n",
    "IDs = ['id_00']\n",
    "\n",
    "AUCs = []\n",
    "\n",
    "latent_space = []\n",
    "\n",
    "for ID in IDs:\n",
    "\n",
    "    # Get data\n",
    "    #ID = IDs[2]\n",
    "    status = stati[0] # normal\n",
    "    name = names[0]\n",
    "    data_path = folder + name + '/' + ID + '/' + status\n",
    "    df_PSD_normal = PSD_DF_Maker(user_path, data_path)\n",
    "\n",
    "    status = stati[1] # abnormal\n",
    "    data_path = folder + name + '/' + ID + '/' + status\n",
    "    df_PSD_abnormal = PSD_DF_Maker(user_path, data_path)\n",
    "\n",
    "    # Create datasets for training/evaluation\n",
    "    train_set, test_set, test_labels = Train_test_sets_maker.fun(df_PSD_normal,df_PSD_abnormal)\n",
    "    # Normalize\n",
    "    MIN,MAX = MinMaxNormalisation.getMinMax(train_set)\n",
    "    train_set = MinMaxNormalisation.fun(train_set,MIN,MAX)\n",
    "    test_set = MinMaxNormalisation.fun(test_set,MIN,MAX)\n",
    "\n",
    "\n",
    "    # Train algorithm\n",
    "    autoencoder = fun(train_set.shape[1])\n",
    "    history = autoencoder.fit(train_set, train_set, \n",
    "                              epochs=50, \n",
    "                              batch_size=512,\n",
    "                              validation_data=(test_set,test_set),\n",
    "                              validation_split = 0.1,\n",
    "                              verbose = 1,\n",
    "                              shuffle=True\n",
    "                             )\n",
    "    \n",
    "    lossValues = lossCalcMSE(autoencoder, test_set)\n",
    "    AUCs.append(metrics.roc_auc_score(~test_labels, lossValues))      \n",
    "    \n",
    "tf_test_set = tf.cast(test_set,float)\n",
    "encoded_data = autoencoder.encoder(tf_test_set,192).numpy()\n",
    "feature_name = ['1','2','3']\n",
    "for data in encoded_data:\n",
    "    plt.bar(feature_name, data, alpha=0.1)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bd8eee6f-f6ab-418e-a417-4a626298b8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9407180242561077]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUCs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5088ef15-8897-4034-ad1f-385a9a6e30ba",
   "metadata": {},
   "source": [
    "## It seems it is better to have fewer latent space dimension if possible. The AUCs appears greater."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa744ed8-5648-4340-9008-d76ca05e6628",
   "metadata": {},
   "source": [
    "What is the network gets progressively shorter :  128,64,32,16,8,2,1 and reverse ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d8429831-bb51-4803-b166-dd5753bde6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train & test sets created !\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 188ms/step - loss: 0.0035 - val_loss: 0.0253\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0034 - val_loss: 0.0252\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0034 - val_loss: 0.0252\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0033 - val_loss: 0.0251\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0033 - val_loss: 0.0250\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0032 - val_loss: 0.0250\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0032 - val_loss: 0.0249\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0031 - val_loss: 0.0248\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0031 - val_loss: 0.0248\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0030 - val_loss: 0.0247\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0030 - val_loss: 0.0247\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0030 - val_loss: 0.0246\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0029 - val_loss: 0.0245\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0029 - val_loss: 0.0245\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0029 - val_loss: 0.0244\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0028 - val_loss: 0.0244\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0028 - val_loss: 0.0243\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0028 - val_loss: 0.0243\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0028 - val_loss: 0.0242\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0027 - val_loss: 0.0242\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0027 - val_loss: 0.0241\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0027 - val_loss: 0.0241\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0026 - val_loss: 0.0240\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0026 - val_loss: 0.0240\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0026 - val_loss: 0.0239\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0026 - val_loss: 0.0239\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0025 - val_loss: 0.0238\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0025 - val_loss: 0.0238\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0025 - val_loss: 0.0237\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0025 - val_loss: 0.0237\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0024 - val_loss: 0.0237\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0024 - val_loss: 0.0236\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0024 - val_loss: 0.0236\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0024 - val_loss: 0.0235\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0024 - val_loss: 0.0235\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0023 - val_loss: 0.0234\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0023 - val_loss: 0.0234\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0023 - val_loss: 0.0234\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0023 - val_loss: 0.0233\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0022 - val_loss: 0.0233\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0022 - val_loss: 0.0232\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0022 - val_loss: 0.0232\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0022 - val_loss: 0.0231\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0022 - val_loss: 0.0231\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0021 - val_loss: 0.0231\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0021 - val_loss: 0.0230\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0021 - val_loss: 0.0230\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0021 - val_loss: 0.0230\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0021 - val_loss: 0.0229\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0020 - val_loss: 0.0229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPv0lEQVR4nO3df6xfd13H8edr3Vq2scnK1vZ2P2yBMlINIXApxsSodCVdg+v+ULIZkxuYNhJn1IRAsYnBf0wFEoJhcbmZy2pCNmf80f5xzeia6GKy6S6EwQbO1ins0st66dTEECiFt3/0VL/tvrf3x7ntveXzfCTNOZ9f57z7z/fVc873fJuqQpLUriuWuwBJ0vIyCCSpcQaBJDXOIJCkxhkEktQ4g0CSGrckQZBkZ5IXkxxLsnfIeJL8STf+lSTvnO9aSdLF1TsIkqwCHgDuBLYC9ybZet60O4Et3Z89wJ8uYK0k6SJaiiuCbcCxqnqpqk4BjwG7z5uzG/jzOuMZ4A1JRua5VpJ0EV25BMe4GXh5oD0FvGcec26e51oAkuzhzNUE11577bve9ra3LarYf//28UWtk6SVYPOGjYte+8UvfvE7VXXT+f1LEQQZ0nf+71bMNmc+a890Vo0D4wCjo6M1OTm5kBr/z69/4vcXtU6SVoKHPvFHi16b5BvD+pciCKaAWwfatwDn/7N7tjmr57F2aWVY9khSu5YiCJ4FtiTZDHwLuAf41fPmHALuT/IYZ279/HdVTSeZmcfapVV+Y1aSBvUOgqo6neR+4AlgFfBwVb2Q5De78QeBCWAXcAz4LvDBC63tW9OFXHPqdRfz8JJ02VmKKwKqaoIzH/aDfQ8O7BfwW/NdezF9f7VBIEmDvE8iSY1bkiuCy8vp5S5AklaU5oJgzQ+/v9wlSNKK0lwQlN8akqRzNBcEw99hk6R2tRcEZRBI0qDmgsAXiyXpXM0FwRW1arlLkKQVpbkgIGuWuwJJWlGaC4LX/eDUcpcgSStKc0FQeGtIkgY1FwQ/5IfLXYIkrSjNBcGaq3yhTJIGNRcEp1atXu4SJGlFaS4IfuAzAkk6R3NB8KMrvrfcJUjSitJcELCqvb+yJF1Ic5+K/7PK9wgkaVBzQcAV/tiQJA1qLgiuPuV/TCNJg3oFQZK1wF8Am4D/AD5QVf85ZN5O4LPAKuChqtrf9X8K+CXgFPBvwAer6r/61DSXq/nRxTy8JF12+l4R7AWOVNX+JHu79scGJyRZBTwA7ACmgGeTHKqqrwGHgY9X1ekkfwx8/Pz1S+1aHxZL0jn6firuBn6h2z8A/D2v/SDfBhyrqpcAkjzWrftaVX1hYN4zwC/3rGdOvlcsSefqGwTrq2oaoKqmk6wbMudm4OWB9hTwniHzPsSZ20xDJdkD7AG47bbbFl0wV3trSJIGzRkESZ4ENgwZ2jfPcwz7mk6dd459wGng87MdpKrGgXGA0dHRmm3enMWsWvRSSfqxNGcQVNUds40leSXJSHc1MAKcGDJtCrh1oH0LcHzgGGPA+4HtVXXRP6Wz5qqLfQpJuqz0vWV+CBjr9seAg0PmPAtsSbI5yWrgnm7d2W8TfQy4q6q+27MWSdIi9A2C/cCOJEc5862gs18L3ZhkAqCqTgP3A08AXwcer6oXuvWfA64DDif5cpIHe9YjSVqgXg+Lq+oksH1I/3Fg10B7ApgYMu8tfc4vSeqvuS/Vr7v69ctdgiStKM0FwfVX+LBYkgb5fpUkNc4gkKTGGQSS1DiDQJIaZxBIUuOa+9bQddffuNwlSNKK0lwQrF6zZrlLkKQVxVtDktQ4g0CSGmcQSFLjDAJJalxzD4uvu+mNy12CJK0oXhFIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxvUKgiRrkxxOcrTb3jDLvJ1JXkxyLMneIeMfSVJJ/EU4SbrE+l4R7AWOVNUW4EjXPkeSVcADwJ3AVuDeJFsHxm8FdgDf7FmLJGkR+gbBbuBAt38AuHvInG3Asap6qapOAY916876DPBRoHrWIklahL5BsL6qpgG67bohc24GXh5oT3V9JLkL+FZVPTfXiZLsSTKZZHJmZqZn2ZKks+b8iYkkTwIbhgztm+c5MqSvklzTHeN98zlIVY0D4wCjo6NePUjSEpkzCKrqjtnGkrySZKSqppOMACeGTJsCbh1o3wIcB94MbAaeS3K2/0tJtlXVtxfwd5Ak9dD31tAhYKzbHwMODpnzLLAlyeYkq4F7gENV9dWqWldVm6pqE2cC452GgCRdWn2DYD+wI8lRznzzZz9Ako1JJgCq6jRwP/AE8HXg8ap6oed5JUlLpNfPUFfVSWD7kP7jwK6B9gQwMcexNvWpRZK0OL5ZLEmNa+4/prn6mjXLXYIkrSheEUhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDWuuV8fvfKqtctdgiStKF4RSFLjDAJJapxBIEmNa+4ZwU2vv2q5S5CkFaXXFUGStUkOJznabW+YZd7OJC8mOZZk73ljv92NvZDkk33qkSQtXN9bQ3uBI1W1BTjStc+RZBXwAHAnsBW4N8nWbuwXgd3A26vqp4BP96xHkrRAfYNgN3Cg2z8A3D1kzjbgWFW9VFWngMe6dQAfBvZX1fcBqupEz3okSQvUNwjWV9U0QLddN2TOzcDLA+2prg/grcDPJfmnJP+Q5N2znSjJniSTSSZnZmZ6li1JOmvOh8VJngQ2DBnaN89zZEhfDZz/BuBngHcDjyd5U1XVaxZUjQPjAKOjo68ZlyQtzpxBUFV3zDaW5JUkI1U1nWQEGHZrZwq4daB9C3B8YOyvuw/+f07yI+BGwH/yS9Il0vfW0CFgrNsfAw4OmfMssCXJ5iSrgXu6dQB/C7wXIMlbgdXAd3rWJElagL5BsB/YkeQosKNrk2RjkgmAqjoN3A88AXwdeLyqXujWPwy8KcnznHmIPDbstpAk6eLp9UJZVZ0Etg/pPw7sGmhPABND5p0Cfq1PDZKkfvyJCUlqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjev1X1Vejm68+o3LXYIkrSi9rgiSrE1yOMnRbnvDLPN2JnkxybEkewf635HkmSRfTjKZZFufeiRJC9f31tBe4EhVbQGOdO1zJFkFPADcCWwF7k2ytRv+JPCHVfUO4A+6tiTpEuobBLuBA93+AeDuIXO2Aceq6qWqOgU81q0DKOD6bv8ngOM965EkLVDfZwTrq2oaoKqmk6wbMudm4OWB9hTwnm7/d4EnknyaM6H0sz3rkSQt0JxBkORJYMOQoX3zPEeG9FW3/TDwe1X1V0k+APwZcMcsdewB9gDcdttt8zy1JGkucwZBVQ39YAZI8kqSke5qYAQ4MWTaFHDrQPsW/v8W0BjwO93+XwIPXaCOcWAcYHR0tGabJ0lamL7PCA5x5sOcbntwyJxngS1JNidZDdzTrYMzgfDz3f57gaM965EkLVDfZwT7gceT3Ad8E/gVgCQbgYeqaldVnU5yP/AEsAp4uKpe6Nb/BvDZJFcC36O79SNJunR6BUFVnQS2D+k/DuwaaE8AE0Pm/SPwrj41SJL68ScmJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUuF5BkGRtksNJjnbbG2aZ93CSE0meX8x6SdLF0/eKYC9wpKq2AEe69jCPADt7rJckXSR9g2A3cKDbPwDcPWxSVT0FvLrY9ZKki6dvEKyvqmmAbrvuYq1PsifJZJLJmZmZRRcsSTrXlXNNSPIksGHI0L6lL2d2VTUOjAOMjo7WpTy3JP04mzMIquqO2caSvJJkpKqmk4wAJxZ4/r7rJUk99b01dAgY6/bHgIOXeL0kqae+QbAf2JHkKLCja5NkY5KJs5OSPAo8DdyeZCrJfRdaL0m6dOa8NXQhVXUS2D6k/ziwa6B970LWS5IuHd8slqTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS43oFQZK1SQ4nOdptb5hl3sNJTiR5/rz+TyX5lyRfSfI3Sd7Qpx5J0sL1vSLYCxypqi3Aka49zCPAziH9h4Gfrqq3A/8KfLxnPZKkBeobBLuBA93+AeDuYZOq6ing1SH9X6iq013zGeCWnvVIkhaobxCsr6ppgG67rsexPgT83WyDSfYkmUwyOTMz0+M0kqRBV841IcmTwIYhQ/uWqogk+4DTwOdnm1NV48A4wOjoaC3VuSWpdXMGQVXdMdtYkleSjFTVdJIR4MRCC0gyBrwf2F5VfsBL0iXW99bQIWCs2x8DDi5kcZKdwMeAu6rquz1rkSQtQt8g2A/sSHIU2NG1SbIxycTZSUkeBZ4Gbk8yleS+buhzwHXA4SRfTvJgz3okSQs0562hC6mqk8D2If3HgV0D7XtnWf+WPueXJPXnm8WS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWpcryBIsjbJ4SRHu+0Ns8x7OMmJJM/PMv6RJJXkxj71SJIWru8VwV7gSFVtAY507WEeAXYOG0hyK7AD+GbPWiRJi9A3CHYDB7r9A8DdwyZV1VPAq7Mc4zPAR4HqWYskaRH6BsH6qpoG6LbrFrI4yV3At6rquXnM3ZNkMsnkzMzM4qqVJL3GlXNNSPIksGHI0L4+J05yTXeM981nflWNA+MAo6OjXj1I0hKZMwiq6o7ZxpK8kmSkqqaTjAAnFnDuNwObgeeSANwCfCnJtqr69gKOI0nqoe+toUPAWLc/Bhyc78Kq+mpVrauqTVW1CZgC3mkISNKl1TcI9gM7khzlzDd/9gMk2Zhk4uykJI8CTwO3J5lKcl/P80qSlsict4YupKpOAtuH9B8Hdg20753HsTb1qWW+Vl2/5lKcRpIuG75ZLEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxqbr8ftE5yQzwjeWuQxriRuA7y12ENIufrKqbzu+8LINAWqmSTFbV6HLXIS2Et4YkqXEGgSQ1ziCQltb4chcgLZTPCCSpcV4RSFLjDAJJapxBIC2BJA8nOZHk+eWuRVoog0BaGo8AO5e7CGkxDAJpCVTVU8Cry12HtBgGgSQ1ziCQpMYZBJLUOINAkhpnEEhLIMmjwNPA7Ummkty33DVJ8+VPTEhS47wikKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcf8LbQf4ssKCgIsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, losses\n",
    "\n",
    "class AnomalyDetector(Model):\n",
    "    \n",
    "  def __init__(self,InputSize):\n",
    "    super(AnomalyDetector, self).__init__()\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Dense(128, activation=\"relu\"),\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(32, activation=\"relu\"),\n",
    "      layers.Dense(16, activation= \"relu\"),\n",
    "      layers.Dense(8, activation = \"relu\"),\n",
    "      layers.Dense(4, activation=\"relu\"),\n",
    "      layers.Dense(2, activation=\"relu\"),\n",
    "      layers.Dense(1, activation=\"selu\"),\n",
    "    ])\n",
    "    \n",
    "\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(2, activation= \"relu\"),\n",
    "      layers.Dense(4, activation= \"relu\"),\n",
    "      layers.Dense(8, activation=\"relu\"),\n",
    "      layers.Dense(16, activation=\"relu\"),\n",
    "      layers.Dense(32, activation=\"relu\"),\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(128, activation=\"relu\"),\n",
    "      layers.Dense(InputSize, activation=\"linear\")])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "def fun(InputSize, loss_fun = \"mse\"):\n",
    "    \n",
    "    AE =  AnomalyDetector(InputSize)\n",
    "    AE.compile(loss=loss_fun,\n",
    "               optimizer='adam'\n",
    "              )\n",
    "    return AE\n",
    "\n",
    "### Path files\n",
    "names = ['fan']\n",
    "stati = ['normal', 'abnormal']\n",
    "SNR = ['+6dB', '-6dB']\n",
    "\n",
    "folder = '/MIMII/RawData/' + SNR[0] + '/' # fan/id_00/abnormal'\n",
    "user_path = 'C:/Users/carbo/Documents/'\n",
    "writer_path = 'C:/Users/carbo/Documents/MIMII/Data/' + SNR[0] +'/PSD/'\n",
    "\n",
    "### Parameters\n",
    "#IDs = ['id_00','id_02', 'id_04', 'id_06']\n",
    "\n",
    "IDs = ['id_00']\n",
    "\n",
    "AUCs = []\n",
    "\n",
    "latent_space = []\n",
    "\n",
    "for ID in IDs:\n",
    "\n",
    "    # Get data\n",
    "    #ID = IDs[2]\n",
    "    status = stati[0] # normal\n",
    "    name = names[0]\n",
    "    data_path = folder + name + '/' + ID + '/' + status\n",
    "    df_PSD_normal = PSD_DF_Maker(user_path, data_path)\n",
    "\n",
    "    status = stati[1] # abnormal\n",
    "    data_path = folder + name + '/' + ID + '/' + status\n",
    "    df_PSD_abnormal = PSD_DF_Maker(user_path, data_path)\n",
    "\n",
    "    # Create datasets for training/evaluation\n",
    "    train_set, test_set, test_labels = Train_test_sets_maker.fun(df_PSD_normal,df_PSD_abnormal)\n",
    "    # Normalize\n",
    "    MIN,MAX = MinMaxNormalisation.getMinMax(train_set)\n",
    "    train_set = MinMaxNormalisation.fun(train_set,MIN,MAX)\n",
    "    test_set = MinMaxNormalisation.fun(test_set,MIN,MAX)\n",
    "\n",
    "\n",
    "    # Train algorithm\n",
    "    autoencoder = fun(train_set.shape[1])\n",
    "    history = autoencoder.fit(train_set, train_set, \n",
    "                              epochs=50, \n",
    "                              batch_size=512,\n",
    "                              validation_data=(test_set,test_set),\n",
    "                              validation_split = 0.1,\n",
    "                              verbose = 1,\n",
    "                              shuffle=True\n",
    "                             )\n",
    "    \n",
    "    lossValues = lossCalcMSE(autoencoder, test_set)\n",
    "    AUCs.append(metrics.roc_auc_score(~test_labels, lossValues))      \n",
    "    \n",
    "tf_test_set = tf.cast(test_set,float)\n",
    "encoded_data = autoencoder.encoder(tf_test_set,192).numpy()\n",
    "feature_name = ['1']\n",
    "for data in encoded_data:\n",
    "    plt.bar(feature_name, data, alpha=0.1)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4a42a3-628a-4fe7-b4b3-7537fdfa3e5d",
   "metadata": {},
   "source": [
    "Si l'autoencoder est trop large avec juste du ReLu, les données se \"perdent\" et on a plus de quoi faire la prédiction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "345b3257-f88c-4534-8f2d-a131d1bb3361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train & test sets created !\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 149ms/step - loss: 0.0035 - val_loss: 0.0252\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0033 - val_loss: 0.0250\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0032 - val_loss: 0.0248\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0031 - val_loss: 0.0246\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0030 - val_loss: 0.0244\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0029 - val_loss: 0.0241\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0027 - val_loss: 0.0238\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0026 - val_loss: 0.0234\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0024 - val_loss: 0.0230\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0023 - val_loss: 0.0225\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0021 - val_loss: 0.0220\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0019 - val_loss: 0.0214\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0017 - val_loss: 0.0208\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0014 - val_loss: 0.0200\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0012 - val_loss: 0.0191\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 9.3026e-04 - val_loss: 0.0182\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 6.9717e-04 - val_loss: 0.0173\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 4.9581e-04 - val_loss: 0.0164\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 3.5117e-04 - val_loss: 0.0156\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.8229e-04 - val_loss: 0.0149\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.7964e-04 - val_loss: 0.0145\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.9633e-04 - val_loss: 0.0144\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.8683e-04 - val_loss: 0.0144\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.5491e-04 - val_loss: 0.0147\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.2480e-04 - val_loss: 0.0149\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.1027e-04 - val_loss: 0.0152\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.0834e-04 - val_loss: 0.0153\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.1170e-04 - val_loss: 0.0154\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.1351e-04 - val_loss: 0.0154\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.1044e-04 - val_loss: 0.0154\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.0364e-04 - val_loss: 0.0153\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.9564e-04 - val_loss: 0.0152\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.8898e-04 - val_loss: 0.0151\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.8471e-04 - val_loss: 0.0150\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.8346e-04 - val_loss: 0.0149\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.8377e-04 - val_loss: 0.0149\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.8472e-04 - val_loss: 0.0149\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.8480e-04 - val_loss: 0.0149\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.8386e-04 - val_loss: 0.0149\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.8227e-04 - val_loss: 0.0149\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.8095e-04 - val_loss: 0.0149\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.8007e-04 - val_loss: 0.0149\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.7952e-04 - val_loss: 0.0149\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.7934e-04 - val_loss: 0.0149\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7886e-04 - val_loss: 0.0149\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.7802e-04 - val_loss: 0.0148\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.7731e-04 - val_loss: 0.0147\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7671e-04 - val_loss: 0.0147\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7595e-04 - val_loss: 0.0147\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7539e-04 - val_loss: 0.0146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, losses\n",
    "\n",
    "class AnomalyDetector(Model):\n",
    "    \n",
    "  def __init__(self,InputSize):\n",
    "    super(AnomalyDetector, self).__init__()\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(8, activation=\"relu\"),\n",
    "      layers.Dense(8, activation= \"relu\"),\n",
    "      layers.Dense(3, activation = \"selu\"),\n",
    "    ])\n",
    "    \n",
    "\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(8, activation=\"relu\"),\n",
    "      layers.Dense(8, activation=\"relu\"),\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(InputSize, activation=\"linear\")])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "def fun(InputSize, loss_fun = \"mse\"):\n",
    "    \n",
    "    AE =  AnomalyDetector(InputSize)\n",
    "    AE.compile(loss=loss_fun,\n",
    "               optimizer='adam'\n",
    "              )\n",
    "    return AE\n",
    "\n",
    "### Path files\n",
    "names = ['fan']\n",
    "stati = ['normal', 'abnormal']\n",
    "SNR = ['+6dB', '-6dB']\n",
    "\n",
    "folder = '/MIMII/RawData/' + SNR[0] + '/' # fan/id_00/abnormal'\n",
    "user_path = 'C:/Users/carbo/Documents/'\n",
    "writer_path = 'C:/Users/carbo/Documents/MIMII/Data/' + SNR[0] +'/PSD/'\n",
    "\n",
    "### Parameters\n",
    "#IDs = ['id_00','id_02', 'id_04', 'id_06']\n",
    "\n",
    "IDs = ['id_00']\n",
    "\n",
    "AUCs = []\n",
    "\n",
    "latent_space = []\n",
    "\n",
    "for ID in IDs:\n",
    "\n",
    "    # Get data\n",
    "    #ID = IDs[2]\n",
    "    status = stati[0] # normal\n",
    "    name = names[0]\n",
    "    data_path = folder + name + '/' + ID + '/' + status\n",
    "    df_PSD_normal = PSD_DF_Maker(user_path, data_path)\n",
    "\n",
    "    status = stati[1] # abnormal\n",
    "    data_path = folder + name + '/' + ID + '/' + status\n",
    "    df_PSD_abnormal = PSD_DF_Maker(user_path, data_path)\n",
    "\n",
    "    # Create datasets for training/evaluation\n",
    "    train_set, test_set, test_labels = Train_test_sets_maker.fun(df_PSD_normal,df_PSD_abnormal)\n",
    "    # Normalize\n",
    "    MIN,MAX = MinMaxNormalisation.getMinMax(train_set)\n",
    "    train_set = MinMaxNormalisation.fun(train_set,MIN,MAX)\n",
    "    test_set = MinMaxNormalisation.fun(test_set,MIN,MAX)\n",
    "\n",
    "\n",
    "    # Train algorithm\n",
    "    autoencoder = fun(train_set.shape[1])\n",
    "    history = autoencoder.fit(train_set, train_set, \n",
    "                              epochs=50, \n",
    "                              batch_size=512,\n",
    "                              validation_data=(test_set,test_set),\n",
    "                              validation_split = 0.1,\n",
    "                              verbose = 1,\n",
    "                              shuffle=True\n",
    "                             )\n",
    "    \n",
    "    lossValues = lossCalcMSE(autoencoder, test_set)\n",
    "    AUCs.append(metrics.roc_auc_score(~test_labels, lossValues))      \n",
    "    \n",
    "tf_test_set = tf.cast(test_set,float)\n",
    "encoded_data = autoencoder.encoder(tf_test_set,192).numpy()\n",
    "feature_name = ['1','2','3']\n",
    "for data in encoded_data:\n",
    "    plt.bar(feature_name, data, alpha=0.1)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "807684af-5e9b-4c8e-8f3b-437a52de7e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9550253850008149]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e8618839-04d4-48e5-8427-cd9c611654a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2bc92ec1-eb37-47b8-a97c-9b2f760f3f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = df.corr(\n",
    "    method = 'pearson',  # The method of correlation\n",
    "    min_periods = 1      # Min number of observations required\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fdc8245a-7bd3-48b2-8fb3-dcea945adf98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997083</td>\n",
       "      <td>-0.981335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.997083</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.965026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.981335</td>\n",
       "      <td>-0.965026</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0  1.000000  0.997083 -0.981335\n",
       "1  0.997083  1.000000 -0.965026\n",
       "2 -0.981335 -0.965026  1.000000"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7abd2a-51e4-4952-bd4e-2b138aeee72a",
   "metadata": {},
   "source": [
    "Based on the analysis : the 3 latent space dimension are correlated. We can deduce that only 1D Latent space is enough !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c668e51-a81c-4148-9412-802182a2f215",
   "metadata": {},
   "source": [
    "## Latent space correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2832957f-e543-49f1-8f3e-75d5ed362c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train & test sets created !\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 164ms/step - loss: 0.0035 - val_loss: 0.0252\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0034 - val_loss: 0.0251\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0033 - val_loss: 0.0249\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0032 - val_loss: 0.0247\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0031 - val_loss: 0.0246\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0030 - val_loss: 0.0244\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0029 - val_loss: 0.0242\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0028 - val_loss: 0.0239\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0027 - val_loss: 0.0237\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0025 - val_loss: 0.0235\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0024 - val_loss: 0.0232\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0022 - val_loss: 0.0229\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0021 - val_loss: 0.0226\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0019 - val_loss: 0.0222\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0018 - val_loss: 0.0219\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0016 - val_loss: 0.0215\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0014 - val_loss: 0.0211\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0013 - val_loss: 0.0207\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0011 - val_loss: 0.0203\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 9.5969e-04 - val_loss: 0.0198\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 8.1893e-04 - val_loss: 0.0194\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 6.9520e-04 - val_loss: 0.0189\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 5.8893e-04 - val_loss: 0.0185\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 4.9859e-04 - val_loss: 0.0181\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 4.2576e-04 - val_loss: 0.0177\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3.6945e-04 - val_loss: 0.0174\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3.2540e-04 - val_loss: 0.0171\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.9041e-04 - val_loss: 0.0169\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.5917e-04 - val_loss: 0.0167\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.3429e-04 - val_loss: 0.0166\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.1678e-04 - val_loss: 0.0166\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.0597e-04 - val_loss: 0.0166\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.0153e-04 - val_loss: 0.0166\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.0128e-04 - val_loss: 0.0166\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.0322e-04 - val_loss: 0.0166\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.0527e-04 - val_loss: 0.0166\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.0619e-04 - val_loss: 0.0166\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.0616e-04 - val_loss: 0.0166\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.0456e-04 - val_loss: 0.0166\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.0223e-04 - val_loss: 0.0166\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.9950e-04 - val_loss: 0.0166\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.9687e-04 - val_loss: 0.0166\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.9488e-04 - val_loss: 0.0166\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.9378e-04 - val_loss: 0.0166\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.9300e-04 - val_loss: 0.0166\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.9284e-04 - val_loss: 0.0166\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.9288e-04 - val_loss: 0.0166\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.9290e-04 - val_loss: 0.0166\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.9294e-04 - val_loss: 0.0166\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.9278e-04 - val_loss: 0.0166\n",
      "Train & test sets created !\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 169ms/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 9.8006e-04 - val_loss: 0.0011\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 9.4814e-04 - val_loss: 0.0010\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 9.1775e-04 - val_loss: 0.0010\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 8.8894e-04 - val_loss: 0.0010\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 8.6150e-04 - val_loss: 9.8101e-04\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 8.3542e-04 - val_loss: 9.6213e-04\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 8.1062e-04 - val_loss: 9.4430e-04\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 7.8695e-04 - val_loss: 9.2747e-04\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 7.6439e-04 - val_loss: 9.1156e-04\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 7.4290e-04 - val_loss: 8.9650e-04\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 7.2246e-04 - val_loss: 8.8226e-04\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 7.0286e-04 - val_loss: 8.6881e-04\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 6.8419e-04 - val_loss: 8.5609e-04\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 6.6637e-04 - val_loss: 8.4404e-04\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 6.4929e-04 - val_loss: 8.3264e-04\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 6.3302e-04 - val_loss: 8.2183e-04\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 6.1741e-04 - val_loss: 8.1160e-04\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 6.0246e-04 - val_loss: 8.0189e-04\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 5.8821e-04 - val_loss: 7.9268e-04\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 5.7452e-04 - val_loss: 7.8398e-04\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 5.6141e-04 - val_loss: 7.7576e-04\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 5.4885e-04 - val_loss: 7.6799e-04\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 5.3681e-04 - val_loss: 7.6065e-04\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 5.2526e-04 - val_loss: 7.5371e-04\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 5.1416e-04 - val_loss: 7.4714e-04\n",
      "Train & test sets created !\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 181ms/step - loss: 0.0074 - val_loss: 0.0115\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0072 - val_loss: 0.0112\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0070 - val_loss: 0.0110\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0068 - val_loss: 0.0107\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0066 - val_loss: 0.0104\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0063 - val_loss: 0.0101\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0061 - val_loss: 0.0098\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0095\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0056 - val_loss: 0.0091\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0053 - val_loss: 0.0087\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0050 - val_loss: 0.0083\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0046 - val_loss: 0.0079\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0043 - val_loss: 0.0074\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0039 - val_loss: 0.0069\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0036 - val_loss: 0.0065\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0032 - val_loss: 0.0060\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0029 - val_loss: 0.0055\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0012 - val_loss: 0.0034\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0010 - val_loss: 0.0034\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 9.0829e-04 - val_loss: 0.0034\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 7.9889e-04 - val_loss: 0.0035\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 7.1413e-04 - val_loss: 0.0035\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 6.5119e-04 - val_loss: 0.0035\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 6.0010e-04 - val_loss: 0.0035\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 5.5285e-04 - val_loss: 0.0035\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 5.0810e-04 - val_loss: 0.0035\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 4.6978e-04 - val_loss: 0.0035\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 4.4430e-04 - val_loss: 0.0035\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 4.2813e-04 - val_loss: 0.0035\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 4.1702e-04 - val_loss: 0.0035\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 4.0779e-04 - val_loss: 0.0035\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 4.0079e-04 - val_loss: 0.0035\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.9740e-04 - val_loss: 0.0035\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 3.9666e-04 - val_loss: 0.0035\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 3.9670e-04 - val_loss: 0.0035\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 3.9674e-04 - val_loss: 0.0035\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 3.9631e-04 - val_loss: 0.0035\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.9544e-04 - val_loss: 0.0035\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.9435e-04 - val_loss: 0.0035\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 3.9290e-04 - val_loss: 0.0035\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 3.9130e-04 - val_loss: 0.0035\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.8993e-04 - val_loss: 0.0035\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.8882e-04 - val_loss: 0.0035\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 3.8803e-04 - val_loss: 0.0035\n",
      "Train & test sets created !\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 149ms/step - loss: 0.0057 - val_loss: 0.0075\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0056 - val_loss: 0.0074\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0055 - val_loss: 0.0073\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0053 - val_loss: 0.0072\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0052 - val_loss: 0.0070\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0050 - val_loss: 0.0069\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0048 - val_loss: 0.0067\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0046 - val_loss: 0.0065\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0043 - val_loss: 0.0063\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0041 - val_loss: 0.0060\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0037 - val_loss: 0.0057\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0034 - val_loss: 0.0054\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0012 - val_loss: 0.0035\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 7.8252e-04 - val_loss: 0.0032\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 5.1813e-04 - val_loss: 0.0031\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 4.0576e-04 - val_loss: 0.0030\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 3.9914e-04 - val_loss: 0.0030\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 3.8373e-04 - val_loss: 0.0029\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 3.1026e-04 - val_loss: 0.0029\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.1833e-04 - val_loss: 0.0028\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.5517e-04 - val_loss: 0.0028\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.3262e-04 - val_loss: 0.0028\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.3466e-04 - val_loss: 0.0028\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.4259e-04 - val_loss: 0.0028\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.4507e-04 - val_loss: 0.0028\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.4024e-04 - val_loss: 0.0028\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.3141e-04 - val_loss: 0.0028\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2321e-04 - val_loss: 0.0028\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1741e-04 - val_loss: 0.0028\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.1266e-04 - val_loss: 0.0028\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0895e-04 - val_loss: 0.0028\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0516e-04 - val_loss: 0.0028\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0136e-04 - val_loss: 0.0028\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 9.7880e-05 - val_loss: 0.0028\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 9.5712e-05 - val_loss: 0.0028\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 9.4939e-05 - val_loss: 0.0028\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 9.5268e-05 - val_loss: 0.0028\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 9.5591e-05 - val_loss: 0.0028\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 9.5627e-05 - val_loss: 0.0028\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 9.5253e-05 - val_loss: 0.0028\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 9.4503e-05 - val_loss: 0.0028\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 9.3668e-05 - val_loss: 0.0028\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 9.3059e-05 - val_loss: 0.0028\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 9.2564e-05 - val_loss: 0.0028\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 9.2162e-05 - val_loss: 0.0028\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 9.1939e-05 - val_loss: 0.0028\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, losses\n",
    "\n",
    "class AnomalyDetector(Model):\n",
    "    \n",
    "  def __init__(self,InputSize):\n",
    "    super(AnomalyDetector, self).__init__()\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(8, activation= \"relu\"),\n",
    "      layers.Dense(8, activation = \"relu\"),\n",
    "      layers.Dense(1, activation=\"relu\"),\n",
    "    ])\n",
    "    \n",
    "\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(8, activation= \"relu\"),\n",
    "      layers.Dense(8, activation= \"relu\"),\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(InputSize, activation=\"linear\")])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "def fun(InputSize, loss_fun = \"mse\"):\n",
    "    \n",
    "    AE =  AnomalyDetector(InputSize)\n",
    "    AE.compile(loss=loss_fun,\n",
    "               optimizer='adam'\n",
    "              )\n",
    "    return AE\n",
    "\n",
    "\n",
    "### Path files\n",
    "names = ['fan']\n",
    "stati = ['normal', 'abnormal']\n",
    "SNR = ['+6dB', '-6dB']\n",
    "\n",
    "folder = '/MIMII/RawData/' + SNR[0] + '/' # fan/id_00/abnormal'\n",
    "user_path = 'C:/Users/carbo/Documents/'\n",
    "writer_path = 'C:/Users/carbo/Documents/MIMII/Data/' + SNR[0] +'/PSD/'\n",
    "\n",
    "### Parameters\n",
    "IDs = ['id_00','id_02', 'id_04', 'id_06']\n",
    "\n",
    "AUCs = []\n",
    "\n",
    "latent_space = []\n",
    "\n",
    "for ID in IDs:\n",
    "\n",
    "    # Get data\n",
    "    #ID = IDs[2]\n",
    "    status = stati[0] # normal\n",
    "    name = names[0]\n",
    "    data_path = folder + name + '/' + ID + '/' + status\n",
    "    df_PSD_normal = PSD_DF_Maker(user_path, data_path)\n",
    "\n",
    "    status = stati[1] # abnormal\n",
    "    data_path = folder + name + '/' + ID + '/' + status\n",
    "    df_PSD_abnormal = PSD_DF_Maker(user_path, data_path)\n",
    "\n",
    "    # Create datasets for training/evaluation\n",
    "    train_set, test_set, test_labels = Train_test_sets_maker.fun(df_PSD_normal,df_PSD_abnormal)\n",
    "    # Normalize\n",
    "    MIN,MAX = MinMaxNormalisation.getMinMax(train_set)\n",
    "    train_set = MinMaxNormalisation.fun(train_set,MIN,MAX)\n",
    "    test_set = MinMaxNormalisation.fun(test_set,MIN,MAX)\n",
    "\n",
    "\n",
    "    # Train algorithm\n",
    "    autoencoder = fun(train_set.shape[1])\n",
    "    history = autoencoder.fit(train_set, train_set, \n",
    "                              epochs=50, \n",
    "                              batch_size=512,\n",
    "                              validation_data=(test_set,test_set),\n",
    "                              validation_split = 0.1,\n",
    "                              verbose = 1,\n",
    "                              shuffle=True\n",
    "                             )\n",
    "    \n",
    "    lossValues = lossCalcMSE(autoencoder, test_set)\n",
    "    AUCs.append(metrics.roc_auc_score(~test_labels, lossValues))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c9cbb1aa-f0f4-4f97-9f51-e3c079e205a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9535101328713123, 0.8606233657404894, 0.9855330955212048, 1.0]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUCs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c29b01c-86f6-41bf-a7cc-84430c329da4",
   "metadata": {},
   "source": [
    "Pour autant sur certain dataset où la frontière Normale/Anormale est claire, l'autoencoder permet de bien séparer les données avec seulement un latent space de 1D. Mais lorsqu'il est plus compliqué de séparer, on observe une baisse des performances locales.\n",
    "\n",
    "Conclusion : si la distinction est marquée, avoir une réduction du latent space peut amener à de meileurs résultats. Au contraire si elle est plus floue, le latent space peut ne pas être capable d'efficacement détecter le problème."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d73e1b7-9de3-40ac-8aed-a330cc76242a",
   "metadata": {},
   "source": [
    "## Work on Id_02 : quel devrait-être le latent space dimension pour avoir des propriétés générales performantes ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "cca34d34-162d-4805-a201-9d29765d5e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train & test sets created !\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 155ms/step - loss: 0.0088 - val_loss: 0.0135\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0086 - val_loss: 0.0133\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0084 - val_loss: 0.0131\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0083 - val_loss: 0.0130\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0081 - val_loss: 0.0128\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0080 - val_loss: 0.0126\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0079 - val_loss: 0.0124\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0077 - val_loss: 0.0123\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0076 - val_loss: 0.0121\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0075 - val_loss: 0.0120\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0074 - val_loss: 0.0118\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0073 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0071 - val_loss: 0.0116\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0070 - val_loss: 0.0114\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0069 - val_loss: 0.0113\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0068 - val_loss: 0.0112\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0067 - val_loss: 0.0111\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0066 - val_loss: 0.0110\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0065 - val_loss: 0.0108\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0065 - val_loss: 0.0107\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0064 - val_loss: 0.0106\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0063 - val_loss: 0.0105\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0062 - val_loss: 0.0104\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0061 - val_loss: 0.0103\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0060 - val_loss: 0.0102\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0060 - val_loss: 0.0101\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0059 - val_loss: 0.0100\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0099\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0057 - val_loss: 0.0098\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0057 - val_loss: 0.0098\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0056 - val_loss: 0.0097\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0055 - val_loss: 0.0096\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0054 - val_loss: 0.0095\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0054 - val_loss: 0.0094\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0053 - val_loss: 0.0093\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0053 - val_loss: 0.0093\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0052 - val_loss: 0.0092\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0051 - val_loss: 0.0091\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0051 - val_loss: 0.0090\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0050 - val_loss: 0.0090\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0050 - val_loss: 0.0089\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0049 - val_loss: 0.0088\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0048 - val_loss: 0.0088\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0048 - val_loss: 0.0087\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0047 - val_loss: 0.0086\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0047 - val_loss: 0.0086\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0046 - val_loss: 0.0085\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0046 - val_loss: 0.0085\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0045 - val_loss: 0.0084\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0045 - val_loss: 0.0083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, losses\n",
    "\n",
    "class AnomalyDetector(Model):\n",
    "    \n",
    "  def __init__(self,InputSize):\n",
    "    super(AnomalyDetector, self).__init__()\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(8, activation= \"relu\"),\n",
    "      layers.Dense(8, activation = \"relu\"),\n",
    "      layers.Dense(1, activation=\"relu\"),\n",
    "    ])\n",
    "    \n",
    "\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(8, activation= \"relu\"),\n",
    "      layers.Dense(8, activation= \"relu\"),\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(InputSize, activation=\"linear\")])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "def fun(InputSize, loss_fun = \"mse\"):\n",
    "    \n",
    "    AE =  AnomalyDetector(InputSize)\n",
    "    AE.compile(loss=loss_fun,\n",
    "               optimizer='adam'\n",
    "              )\n",
    "    return AE\n",
    "\n",
    "\n",
    "### Path files\n",
    "names = ['fan']\n",
    "stati = ['normal', 'abnormal']\n",
    "SNR = ['+6dB', '-6dB']\n",
    "\n",
    "folder = '/MIMII/RawData/' + SNR[0] + '/' # fan/id_00/abnormal'\n",
    "user_path = 'C:/Users/carbo/Documents/'\n",
    "writer_path = 'C:/Users/carbo/Documents/MIMII/Data/' + SNR[0] +'/PSD/'\n",
    "\n",
    "### Parameters\n",
    "IDs = ['id_04']\n",
    "\n",
    "AUCs = []\n",
    "\n",
    "latent_space = []\n",
    "\n",
    "for ID in IDs:\n",
    "\n",
    "    # Get data\n",
    "    #ID = IDs[2]\n",
    "    status = stati[0] # normal\n",
    "    name = names[0]\n",
    "    data_path = folder + name + '/' + ID + '/' + status\n",
    "    df_PSD_normal = PSD_DF_Maker(user_path, data_path)\n",
    "\n",
    "    status = stati[1] # abnormal\n",
    "    data_path = folder + name + '/' + ID + '/' + status\n",
    "    df_PSD_abnormal = PSD_DF_Maker(user_path, data_path)\n",
    "\n",
    "    # Create datasets for training/evaluation\n",
    "    train_set, test_set, test_labels = Train_test_sets_maker.fun(df_PSD_normal,df_PSD_abnormal)\n",
    "    # Normalize\n",
    "    MIN,MAX = MinMaxNormalisation.getMinMax(train_set)\n",
    "    train_set = MinMaxNormalisation.fun(train_set,MIN,MAX)\n",
    "    test_set = MinMaxNormalisation.fun(test_set,MIN,MAX)\n",
    "\n",
    "\n",
    "    # Train algorithm\n",
    "    autoencoder = fun(train_set.shape[1])\n",
    "    history = autoencoder.fit(train_set, train_set, \n",
    "                              epochs=50, \n",
    "                              batch_size=512,\n",
    "                              validation_data=(test_set,test_set),\n",
    "                              validation_split = 0.1,\n",
    "                              verbose = 1,\n",
    "                              shuffle=True\n",
    "                             )\n",
    "    \n",
    "    lossValues = lossCalcMSE(autoencoder, test_set)\n",
    "    AUCs.append(metrics.roc_auc_score(~test_labels, lossValues))  \n",
    "    \n",
    "tf_test_set = tf.cast(test_set,float)\n",
    "encoded_data = autoencoder.encoder(tf_test_set,192).numpy()\n",
    "feature_name = ['1']\n",
    "for data in encoded_data:\n",
    "    plt.bar(feature_name, data, alpha=0.1)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "920ef4f8-ea75-4808-98b3-581d7a3eef16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8469992733518299]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abefa1a0-4fc3-465a-a90f-be4b0f5c4077",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_PSD_normal = tf.cast(df_PSD_normal,float)\n",
    "encoded_normal = autoencoder.encoder(tf_PSD_normal,192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "dc0ad8b0-059d-4117-af5a-706cad3614d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_PSD_normal = tf.cast(df_PSD_normal,float)\n",
    "tf_PSD_abnormal = tf.cast(df_PSD_abnormal.iloc[:,:-1],float)\n",
    "\n",
    "MIN,MAX = MinMaxNormalisation.getMinMax(tf_PSD_normal)\n",
    "tf_PSD_normal = MinMaxNormalisation.fun(tf_PSD_normal,MIN,MAX)\n",
    "tf_PSD_abnormal = MinMaxNormalisation.fun(tf_PSD_abnormal,MIN,MAX)\n",
    "\n",
    "encoded_normal = autoencoder.encoder(tf_PSD_normal,192)\n",
    "encoded_abnormal = autoencoder.encoder(tf_PSD_abnormal,192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a91011f9-5e7b-48b2-aacb-d2c626be3a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(encoded_normal,encoded_normal, color='green')\n",
    "plt.scatter(encoded_abnormal,encoded_abnormal, color='red')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1229457b-b0c4-4bc3-ac10-8e1c6b9e5b0e",
   "metadata": {},
   "source": [
    "## visualize reconstruction with different latent space dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "6fd477f9-377f-47a1-b9ef-5a5f1dc53f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train & test sets created !\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 227ms/step - loss: 0.0038 - val_loss: 0.0274\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0036 - val_loss: 0.0272\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0035 - val_loss: 0.0269\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0034 - val_loss: 0.0266\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0033 - val_loss: 0.0263\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0031 - val_loss: 0.0259\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0030 - val_loss: 0.0254\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0028 - val_loss: 0.0248\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0026 - val_loss: 0.0241\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0024 - val_loss: 0.0233\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0022 - val_loss: 0.0223\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0020 - val_loss: 0.0211\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0017 - val_loss: 0.0198\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0014 - val_loss: 0.0182\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0012 - val_loss: 0.0165\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 9.1680e-04 - val_loss: 0.0148\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 7.1267e-04 - val_loss: 0.0132\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 5.5158e-04 - val_loss: 0.0118\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 4.2747e-04 - val_loss: 0.0108\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 3.3704e-04 - val_loss: 0.0101\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.7444e-04 - val_loss: 0.0097\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2.3866e-04 - val_loss: 0.0096\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.2275e-04 - val_loss: 0.0095\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.1795e-04 - val_loss: 0.0095\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.1574e-04 - val_loss: 0.0094\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.1068e-04 - val_loss: 0.0094\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.0347e-04 - val_loss: 0.0093\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.9587e-04 - val_loss: 0.0092\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.8915e-04 - val_loss: 0.0091\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.8302e-04 - val_loss: 0.0091\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.7809e-04 - val_loss: 0.0090\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.7514e-04 - val_loss: 0.0090\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.7306e-04 - val_loss: 0.0089\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.7071e-04 - val_loss: 0.0088\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.6807e-04 - val_loss: 0.0087\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.6566e-04 - val_loss: 0.0086\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.6319e-04 - val_loss: 0.0084\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.6068e-04 - val_loss: 0.0083\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.5860e-04 - val_loss: 0.0082\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.5704e-04 - val_loss: 0.0081\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.5589e-04 - val_loss: 0.0079\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.5496e-04 - val_loss: 0.0078\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.5429e-04 - val_loss: 0.0076\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.5350e-04 - val_loss: 0.0075\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.5241e-04 - val_loss: 0.0074\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.5121e-04 - val_loss: 0.0074\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.5027e-04 - val_loss: 0.0073\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.4926e-04 - val_loss: 0.0072\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.4821e-04 - val_loss: 0.0070\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.4732e-04 - val_loss: 0.0069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, losses\n",
    "\n",
    "class AnomalyDetector(Model):\n",
    "    \n",
    "  def __init__(self,InputSize):\n",
    "    super(AnomalyDetector, self).__init__()\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(64,activation=\"relu\"),\n",
    "      layers.Dense(8, activation = \"relu\"),\n",
    "      layers.Dense(1, activation=\"relu\"),\n",
    "    ])\n",
    "    \n",
    "\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(8, activation= \"relu\"),\n",
    "      layers.Dense(64, activation=\"relu\"),\n",
    "      layers.Dense(64,activation=\"relu\"),\n",
    "      layers.Dense(InputSize, activation=\"linear\")])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "def fun(InputSize, loss_fun = \"mse\"):\n",
    "    \n",
    "    AE =  AnomalyDetector(InputSize)\n",
    "    AE.compile(loss=loss_fun,\n",
    "               optimizer='adam'\n",
    "              )\n",
    "    return AE\n",
    "\n",
    "\n",
    "### Path files\n",
    "names = ['fan']\n",
    "stati = ['normal', 'abnormal']\n",
    "SNR = ['+6dB', '-6dB']\n",
    "\n",
    "folder = '/MIMII/RawData/' + SNR[0] + '/' # fan/id_00/abnormal'\n",
    "user_path = 'C:/Users/carbo/Documents/'\n",
    "writer_path = 'C:/Users/carbo/Documents/MIMII/Data/' + SNR[0] +'/PSD/'\n",
    "\n",
    "### Parameters\n",
    "IDs = ['id_00']\n",
    "\n",
    "AUCs = []\n",
    "\n",
    "latent_space = []\n",
    "\n",
    "for ID in IDs:\n",
    "\n",
    "    # Get data\n",
    "    #ID = IDs[2]\n",
    "    status = stati[0] # normal\n",
    "    name = names[0]\n",
    "    data_path = folder + name + '/' + ID + '/' + status\n",
    "    df_PSD_normal = PSD_DF_Maker(user_path, data_path)\n",
    "\n",
    "    status = stati[1] # abnormal\n",
    "    data_path = folder + name + '/' + ID + '/' + status\n",
    "    df_PSD_abnormal = PSD_DF_Maker(user_path, data_path)\n",
    "\n",
    "    # Create datasets for training/evaluation\n",
    "    train_set, test_set, test_labels = Train_test_sets_maker.fun(df_PSD_normal,df_PSD_abnormal)\n",
    "    # Normalize\n",
    "    MIN,MAX = MinMaxNormalisation.getMinMax(train_set)\n",
    "    train_set = MinMaxNormalisation.fun(train_set,MIN,MAX)\n",
    "    test_set = MinMaxNormalisation.fun(test_set,MIN,MAX)\n",
    "\n",
    "\n",
    "    # Train algorithm\n",
    "    autoencoder = fun(train_set.shape[1])\n",
    "    history = autoencoder.fit(train_set, train_set, \n",
    "                              epochs=50, \n",
    "                              batch_size=512,\n",
    "                              validation_data=(test_set,test_set),\n",
    "                              validation_split = 0.1,\n",
    "                              verbose = 1,\n",
    "                              shuffle=True\n",
    "                             )\n",
    "    \n",
    "    lossValues = lossCalcMSE(autoencoder, test_set)\n",
    "    AUCs.append(metrics.roc_auc_score(~test_labels, lossValues))  \n",
    "    \n",
    "tf_test_set = tf.cast(test_set,float)\n",
    "encoded_data = autoencoder.encoder(tf_test_set,192).numpy()\n",
    "feature_name = ['1']\n",
    "for data in encoded_data:\n",
    "    plt.bar(feature_name, data, alpha=0.1)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "e88e76bb-05bb-49c1-aced-304ddbcba121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9536067226484917]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "def2bf22-5d0d-4f2c-831b-948ecd86fb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAsFklEQVR4nO3deXxddZ3/8dfnnLtladIl6d7SvdCyW4oICDpia3Go28wAzijbICo6Pvy54MPfOI7+ZkZ/OioK2EHlIfNzwRVBLaAwoCBbF6C0paWla7olTZNmv/eecz6/P+5JcpPcJLcl6U1uPs/Hg0fvPefk3k9OLu988j3fc46oKsYYY4qfU+gCjDHGnBoW+MYYM0ZY4BtjzBhhgW+MMWOEBb4xxowRkUK9cVVVlc6ZM6dQb2+MMaPShg0bjqpq9cl8bcECf86cOaxfv75Qb2+MMaOSiOw92a+1IR1jjBkjLPCNMWaMsMA3xpgxomBj+MYYUyjpdJqamho6OjoKXUq/EokEM2fOJBqNDtlrWuAbY8acmpoaxo0bx5w5cxCRQpfTh6pSX19PTU0Nc+fOHbLXzWtIR0RWish2EdkpIrf1s83lIvKiiGwRkT8NWYXGGDPEOjo6mDRp0ogMewARYdKkSUP+F8igHb6IuMCdwBVADbBORB5U1a1Z24wH7gJWquo+EZk8pFUaY8wQG6lh32k46sunw18O7FTVXaqaAu4DVvfa5lrg16q6D0BVa4e2zPw8vq2WA43thXhrY4wZ8fIJ/BnA/qznNeGybIuACSLyhIhsEJEP5HohEblZRNaLyPq6urqTq3gAt/5kI//9zJ4hf11jjBlqDz/8MIsXL2bBggV85StfOSXvmU/g5/q7ovddUyLAG4ArgRXAP4vIoj5fpHq3qi5T1WXV1Sd1ZvCA0r6STAdD/rrGGDOUfN/nox/9KA899BBbt27lpz/9KVu3bh38C1+nfAK/BpiV9XwmcDDHNg+raquqHgX+DJwzNCXmz1fFCyzwjTEj2/PPP8+CBQuYN28esViMq6++mgceeGDY3zefaZnrgIUiMhc4AFxNZsw+2wPAHSISAWLAhcA3h7LQfASq+IHdstEYk79//e0Wth5sGtLXXDK9gn/566X9rj9w4ACzZnX30TNnzuS5554b0hpyGTTwVdUTkVuBRwAXuEdVt4jILeH6Nar6iog8DGwCAuD7qrp5OAvPUSeqmWEdY4wZyXLdS/xUzBrK68QrVV0LrO21bE2v518DvjZ0pZ2Yzs7e821IxxiTv4E68eEyc+ZM9u/vngtTU1PD9OnTh/19i+ZaOp0jOWkb0jHGjHAXXHABO3bsYPfu3aRSKe677z6uuuqqYX/form0QhD+ieTbkI4xZoSLRCLccccdrFixAt/3ueGGG1i6dPj/0iiawO8a0rFZOsaYUWDVqlWsWrXqlL5nEQ3pZALfDtoaY0xuxRP4YWNv0zKNMSa3ogl8v6vDtyEdY8zgck2NHEmGo76iCfzOIR3POnxjzCASiQT19fUjNvQ7r4efSCSG9HWL5qBtYPPwjTF5mjlzJjU1NQzHRRyHSucdr4ZS8QR++IvaOnxjzGCi0eiQ3klqtCiaIZ3OMXzPZukYY0xORRP4nUM6aZuHb4wxORVP4FuHb4wxAyqawPcD5a+cDVR7RwpdijHGjEhFE/iBKrdH7+Rd3trBNzbGmDGoiAIfYqSJaKrQpRhjzIhUNIHvB4qD4qhX6FKMMWZEKprAD1SJSEDEAt8YY3IqnsAPz7B1LfCNMSanogl8P8gEvavpAldijDEjU9EEvvqZwI/g2yWSjTEmhyIKfB+AKJ7d9coYY3IomsAPwg4/im9n2xpjTA7FE/hhVx/Fs8A3xpgciibwVTNDOhHxbUjHGGNyyCvwRWSliGwXkZ0icluO9ZeLyHEReTH87wtDX+rAgnAMP4Zn18Q3xpgcBr0Bioi4wJ3AFUANsE5EHlTVrb02fVJV3zkMNeZFg+5ZOnZfW2OM6SufDn85sFNVd6lqCrgPWD28ZZ04DbJm6dgYvjHG9JFP4M8A9mc9rwmX9XaRiLwkIg+JyNJcLyQiN4vIehFZP9T3kuyclhnBtyEdY4zJIZ/AlxzLeifqRuA0VT0H+A7wm1wvpKp3q+oyVV1WXV19QoUOJgiyx/BtSMcYY3rLJ/BrgFlZz2cCB7M3UNUmVW0JH68FoiJSNWRV5qHrTFuxefjGGJNLPoG/DlgoInNFJAZcDTyYvYGITBURCR8vD1+3fqiLHYhq9zx8O2hrjDF9DTpLR1U9EbkVeARwgXtUdYuI3BKuXwO8D/iwiHhAO3C1qp7SNjvIOmhr19Ixxpi+Bg186BqmWdtr2Zqsx3cAdwxtaSco6D5om7YhHWOM6aN4zrQNOq+lYwdtjTEml6IJ/K4zbcXH8yzwjTGmt6IJfMJr6QD4vt0ExRhjeiuawO880xbAT6cKWIkxxoxMxRn4ngW+Mcb0VjSBT1bgq2+Bb4wxvRVN4GvWzJzAhnSMMaaPIgr87g4/8OygrTHG9FY0gZ89SyfwkwUsxBhjRqaiCfzsDl+twzfGmD6KM/DtoK0xxvRRNIEvamP4xhgzkKIJ/OwOHwt8Y4zpo2gCP3sePoEN6RhjTG/FE/jaPQ9f7Vo6xhjTR9EEvh20NcaYgRVN4Gd3+DaGb4wxfRVP4PcYw7fAN8aY3ooy8MUO2hpjTB/FE/iaPYbvFbAQY4wZmYom8LNPvHJsSMcYY/oomsDvceKVTcs0xpg+iibws2fpiHX4xhjTR16BLyIrRWS7iOwUkdsG2O4CEfFF5H1DV2J+sod0LPCNMaavQQNfRFzgTuAdwBLgGhFZ0s92XwUeGeoi8xJkd/h20NYYY3rLp8NfDuxU1V2qmgLuA1bn2O5jwK+A2iGsL3920NYYYwaUT+DPAPZnPa8Jl3URkRnAu4E1A72QiNwsIutFZH1dXd2J1jogCcfwAwSswzfGmD7yCXzJsUx7Pf8W8FnVrDY71xep3q2qy1R1WXV1dZ4l5qdzDD8lMVy1Dt8YY3qL5LFNDTAr6/lM4GCvbZYB94kIQBWwSkQ8Vf3NUBSZl7DD9yRmY/jGGJNDPoG/DlgoInOBA8DVwLXZG6jq3M7HIvJD4HenNOwBAh8fB5+IdfjGGJPDoIGvqp6I3Epm9o0L3KOqW0TklnD9gOP2p4oQoAi+E8WxDt8YY/rIp8NHVdcCa3styxn0qnrd6y/rJAQ+AQ6+RHCswzfGmD6K5kxb0YAAh0AiuGodvjHG9FY8gY9PIJkO3wLfGGP6KprAJwg7fCdqgW+MMTkUTeA7+AS44ZCOjeEbY0xvRRP4opkhncCJ4jLg+V/GGDMmFU3gEx60VYkQsQ7fGGP6KJrAFw3QcAw/MvAVHowxZkwqqsAPxEGdKBHsoK0xxvRWRIHvd3f4eARB7+u7GWPM2FY8gU+mw8eNEMUjnXVDFGOMMUUU+I4GKC7qRImKj+dbh2+MMdmKJvA7p2XiRIni4dmQjjHG9FA8gU+Adh209fF8G9IxxphsRRP4jgYEuOBah2+MMbkUTeCLBiASBr5P2jp8Y4zpoXgCn7DDd2KZDt8O2hpjTA9FE/iO+mg4LTMiAb5NyzTGmB6KJ/AJUHHBjQHge6kCV2SMMSNL0QS+aBB2+FEA/LQFvjHGZCuawHfCaZkSdviBdfjGGNNDkQW+C5Gww/eSBa7IGGNGluIJ/PCgrYRDOoFn18Q3xphsRRP4ggIOTueQjo3hG2NMD0UT+J1DOhIO6ahvHb4xxmTLK/BFZKWIbBeRnSJyW471q0Vkk4i8KCLrReSSoS91YE44S0ecCAC+Bb4xxvQQGWwDEXGBO4ErgBpgnYg8qKpbszZ7DHhQVVVEzgZ+Dpw+HAX3x8HHExens8O3WTrGGNNDPh3+cmCnqu5S1RRwH7A6ewNVbVHVzmsZlAGn/LoGDgE4LuJmfocFvt3m0BhjsuUT+DOA/VnPa8JlPYjIu0VkG/B74IZcLyQiN4dDPuvr6upOpt5+dc7D7zxoa2P4xhjTUz6BLzmW9engVfV+VT0deBfw5VwvpKp3q+oyVV1WXV19QoUOxiWArCEd36ZlGmNMD/kEfg0wK+v5TOBgfxur6p+B+SJS9TprOyHdHX4m8LEO3xhjesgn8NcBC0VkrojEgKuBB7M3EJEFIiLh4/OBGFA/1MX2R1Uz8/DFwQ07/CCwMXxjjMk26CwdVfVE5FbgEcAF7lHVLSJyS7h+DfBe4AMikgbagb/LOog77ALNDOmouF2Bjx20NcaYHgYNfABVXQus7bVsTdbjrwJfHdrS8ucHGo7hZ51pa4FvjDE9FMWZtoFq17RMJxL+DvNtHr4xxmQrmsDvGtKJdk7LtA7fGGOyFUXg+0HY4YuLG554RWCzdIwxJltRBH4QhPPwHRcnEnb4gV/gqowxZmQpjsDX7oO2kYjNwzfGmFyKIvD9cB6+OA5u2OHbtExjjOmpKAI/+6AtjhsutA7fGGOyFUfgBxCRzEFbOi+tYGfaGmNMD0UR+H54gFYcF5zOWToW+MYYk60oAj/wMuGujgtOpsMXC3xjjOmhOAI/DHfpMYZvgW+MMdmKI/D9cM6944IIHi6iFvjGGJOtOAK/8yQryXw7Pq5NyzTGmF6KIvC166Bt5tuxDt8YY/oqisAPsmfpkOnw7aCtMcb0VByB3zl8I5kpmb5Yh2+MMb0VReCrbx2+McYMpjgCv3NIxw0P2koEx66WaYwxPRRF4HfOw1cJO3yJ2JCOMcb0UhyBHw7pOOFlFQJcHLUO3xhjshVF4Hfd7KRzDF9cHLtapjHG9FAUgR/4AdA9Dz+QCGIdvjHG9FAUga/Z19IhE/iOjeEbY0wPRRL4nbN0OgPfxcUC3xhjsuUV+CKyUkS2i8hOEbktx/r3i8im8L+nReScoS+1f10dvpPd4duQjjHGZBs08CUzTnIn8A5gCXCNiCzptdlu4DJVPRv4MnD3UBc6EA06x/Azs3RUXFwb0jHGmB7y6fCXAztVdZeqpoD7gNXZG6jq06raED59Fpg5tGUOTP3ODj/rxCvr8I0xpod8An8GsD/reU24rD83Ag/lWiEiN4vIehFZX1dXl3+Vgwi089IKWR0+FvjGGJMtn8CXHMs054YibyET+J/NtV5V71bVZaq6rLq6Ov8qBxMetHU6D9o6uTv89pRPEOQs3Rhjil4+gV8DzMp6PhM42HsjETkb+D6wWlXrh6a8/HSN4YfTMnEifcbw/UB589ce58fP7T2VpRljzIiRT+CvAxaKyFwRiQFXAw9mbyAis4FfA/+gqq8OfZkDC7o6/O4Tr3oP6dQ0tFHXnKSmof1Ul2eMMSNCZLANVNUTkVuBRwAXuEdVt4jILeH6NcAXgEnAXSIC4KnqsuEru6euSyGHY/g4LpFegb+rrpWZUouXnHKqyjLGmBFl0MAHUNW1wNpey9ZkPb4JuGloS8tfV4ffNQ8/ittrDH/3kQYejt3Gnw5fD5yy30XGGDNiFMeZtp1Xy3Q7O/y+QzrNB7dRLh0kUqf08IIxxowYRRH4aOagLeE8fM0R+EFt5tCC43ec0tKMMWakKIrA77y0QneH33cMv7RpJwCuZ4FvjBmbiiLw0Z5j+OpEidA9574l6TE1tQ8AN0gWpkZjjCmwogj87mvpuOG/ESL4eGHg765rZYEcAMC1IR1jzBhVFIHffaZteGkFN0JUfPzwxii76pqYJ4cAiAYW+MaYsakoAr/zeviu032mLYDnZ25zeLRmJyWSAiCqNqRjjBmbiiLwO8fwcTsDPwqA72UC363PzNBpc8cRszF8Y8wYVRyB39Xhh7N0wqGdzsAf37obgMOli4lp6tTXZ4wxI0CRBH5mrL7zapnSq8MfnzxAs5TTGp9MDOvwjTFjU3EEvva8p233kE6mm494rbRKORopIUEKLzyYa4wxY0lRBL72GtLpupl5OnNCVtRvJ+UkIJogQYoOzwLfGDP2FEXgd15aofPEK3EzHb4XdvjRoJ20WwLRUkpI0pGy+90aY8ae4gj8Xne86gz8IJyWGfMzgS+RBK4oHUmbi2+MGXuKI/A7p2V2zsN3ex60jWs7nluKxEoBSLW3nfISjTGm0Ior8MNbHDrhWH7gZYZu4tqBHynBiZUAkOpoOfU1GmNMgRVH4Aedl0cOh3QinUM6mSmYJdpBECnD7ezwO6zDN8aMPUUR+NKrw5fwxKvA9wgCpYQkQbQUN5EJfM8C3xgzBhVF4KfSmbF6es3SCbw0HWmPUpJotIxI2OGnk60FqdMYYwqpKAK/pT28XIJkvh0nDHz1PdrbWnBEkVgpkXjY4SetwzfGjD3FEfgdSQIERABwIt1n2ibbmgGQWDnRRFlmuQW+MWYMGvWBHwRKW0cKle5vxe28Lr7vkWoPAz9eRjQcww9SFvjGmLFn1Ad+XUsyc6ZteMAWumfpqJ8m2ZaZgunGy4mVZDr8IGUnXhljxp5RH/g1DW049Ax8140BmcD3wg7fTZQRD4d0NG0dvjFm7Mkr8EVkpYhsF5GdInJbjvWni8gzIpIUkU8NfZn9q2loZ6I0o/GKrmWdY/hB4JEOT7KKJMYRjXcGfvupLNEYY0aEQQNfRFzgTuAdwBLgGhFZ0muzY8DHga8PeYWDqGloZ6nsgalndS3rvLctfoogmQn8WEk5RDNn2mKBb4wZg/Lp8JcDO1V1l6qmgPuA1dkbqGqtqq4D0sNQ44COHGtkoVNDZMY5XcucSOeQjocXdvjRknEQSQAgngW+MWbsieSxzQxgf9bzGuDCk3kzEbkZuBlg9uzZJ/MS3Rr3A4rUvkKEAKZ1B74b6ezwPTSdubxCvHQcOA5JYohnB22NMWNPPoEvOZbpybyZqt4N3A2wbNmyk3qNTh3334p7fD+V7SsyC6ae3bUuEoln3s/3ug7QxsoyY/xJYjjW4RtjxqB8hnRqgFlZz2cCB4ennPzVHtxHtPE1ruz4LR1uOUyY07Wus8NXPw2pzGUUSsvGAZCWGI5v97U1xow9+QT+OmChiMwVkRhwNfDg8JY1uLiXmW65WPbTUHF611m2AE40HMMPPEi3kdQo0XBZykng+tbhG2PGnkGHdFTVE5FbgUcAF7hHVbeIyC3h+jUiMhVYD1QAgYh8Aliiqk3DVXi5thAgOCgls8/rsS4SdvgSpHHSrbQTJx6uSztxItbhG2PGoHzG8FHVtcDaXsvWZD0+TGao59TwPcpo55Xxl3HG8ScZv/jSHqvdSHeH73httEuC8eG6tJPAtcA3xoxBo/JM23RbIwC1E5bBJ16GM67qsT4SzfTz4ntEvDaSkuha5ztxYoHN0jHGjD2jMvBbjh8FwCkdD5Uze4zfAziOQ6ACgYfrtZN0SrrW+W6cqFqHb4wZe0Zl4LcerwcgUjY+53oRwcOFIE00aOsR+IFbQswC3xgzBo3KwO9oOgZArHxiv9t4uKA+Mb+DdHbgRxLENDXsNRpjzEgzKgM/2ZIJ/MS4gQNf/DSxoB0vUtq1PIiUECeF6us678sYY0adURn46dYGAEorJ/W7jS8uoj5x7cBzuzt8IgkSJEl6wXCXaYwxI8qoDHy/LRP45ZVV/W+DiwRpEtqOn9XhEy0hQYpk2gLfGDO2jMrA1/bjpNWloqKy320yge+RIIlGuwPfiZYQE5+mNjvb1hgztozKwJeORpooIx7t/7wxjwgRv4MoPkG0rGv5+MrMRdR2HqjL782aDoGN9xtjisCoDHw31USrlA24TSAOcT9zvR2yOvzJEycAsONA7eBvVLMBvnE63LMSnv0uPHQbHN1x0nUbY0wh5XVphZEmmmqizR034Da+RIh5mZufEO/+5RCvmgNA474twEUDv9HuJzL/HtsFD9/W/fj9Pz/xoo0xpsBGZYcf85ozl0QegI9LpReekRvL+mtg1nIAKuo2dC3acaSZP7+aY4hn//MwaSF8YhN88hV4y/+GHY/AoZde/zdhjDGn2KgM/BK/mVS0YsBtfIlQ5ddxXEtpqnpD1hdP4FjZfE5PbaGuOcmRpg6u/f5z3PKjDSQ9v3s7VahZR8vk89FIAiqmw4U3Q7wSnvzPYfrOjDFm+IzKwC8LmvFiAwd+IC4BwsfTH0MrZ/RYl5q+nPOdV9m49ygf+fFG6pqTtKV81u1u6N7o2C5oq+ffNpVz+2PhuH2iEpb/I2x9EGq3nVzxqgThfXaNMeZUGn2Br0q5thLE+5+SCfC7knfxydSH2Vq2nOVzep6RW7n4Uiqknbt+9js27G3g9+c8zV2xb/P4tiPdG+1/HoCNwUK+9egOHnjxQGb5Gz8C0RJ46hsnXPqGza+w+d8vofkri2k9vPOEv94YY16PURf4XkcLUfEz3fYAdk9dyfYpq/jNRy9mamWix7qS+RcDcB7b+MVbmli6/Q5WOc9S88ozXdvUb3+KZi1h9RVv5fzZ4/mn+17k3Xf9hR0tMVh2A7z8y8xfAXl69oUXmfmLlcxP70DUp+XHHwDPruljjDl1Rl3gNx/PXEdHSsYPuN23rzmP33/sEmaML+m7cvxppEun8M+lv+KCjZ+B6jPwnDgXNz3Mvvo2UCW96yleZgHvv2geP77pjXxp9VL21bfxkR9vpOOCj6BOBP/RL+U1R7+usZnyB26kXFLITY/yw+pPM6V5C+n/uoyjf/g6BP6gr2GMMa/XqAv81vBa+JHSCQNu5zqC40julSJEr/oW7uKVMON8+Nt76VhwJe9y/8Kjm/bQ8No6pib3cHTWCipLopTEXD5w0Ry+8XfnsqO2hWvv28O30u/C3Xo/z/zq9gEvxBYEysYffJwz2Unj279JYubZXPzXN/Cp9IfYfCRF1dNfZvuv/w+NbSm+/Lut7DjSfNL7xhhjBjLq5uG353Fp5LycvirzX6j8ouvh1V9z+KkfsntSHQmNcdbKG3p8yWWLqrnuTXO495k9zDrrZjbt2c65L/8ba8efzZVve2vOt3n8Nz9gRfOveWX2tZzxpqsBeMNpE3juipt5PHkDrRs+yYWbb+dz+2bwy9qp3P/CAX5044UsmT7wQWljjDlRUqjLBC9btkzXr19/wl+3+X/u48w/f4it73yAJcsuH7qCgoDmNVcQPfISHi4vlV/CxZ/+VY7NlGNtKarK42jzYY5/80Lqg3Iq/+kpqiZk/dVR/xp7nvoZEzd+h/r4LOZ85kkkEu/zenv276Ps+5dSLY2k3VI6fNims3no3Lu4/rIzmDWxtM/XGGPGLhHZoKrLTuZrR12H3+wJrwYzKB1fPbQv7DiM++DPqP3mJUz2DlH2xuv72UyoKg/vmTtuKq1Xfpe5D17LpjtX86eZ7+Ki885m2tFn0Ke+xRz1eNWdz+TrfpIz7AHmzJrNpvc9SOu+x5jj1JJqbeaCzT9i/cbbuXzd1aw+Zzr/ctVSKkuiOb/+WGuKHz27l5cPHCflBXx6xWLOnDHwAW1jzNg06jr8jrRPbVOSqZUJYpGhPwRxaO92djzzWy75m0/iuPm9/oaf/TsLtt1FpXaPv//SfzNPzbqFL33g7VQkcod1v+7/MPryz/nB4u/x1U0JZk8s5Z7rLuC0SWU88OIBntpxlPmTy9l6sIk/bj1Ce9pn8ZRx1LdmrvP/3zcs57zZAx/jMMaMTq+nwx91gT9iBT5HXnuBb//2WTYdhRVvW8GHL1+A29+B44G01sNdb4T2Bg6ccSPv3fImjnkxlp02gadfq6c8HqEl6TGlVPj7ea1cdd4sTlt4FjWtwrXfe462lMcTn34LDa0p1r58iA9cNIeSmDsk32ZNQxt1zUmmjy+hPeUTjzpMq+yeCbX/WBuqMHvS4ENRqkrSC0hE+9bW2JaiNeUzqSyWc70xY9WwB76IrARuB1zg+6r6lV7rJVy/CmgDrlPVjQO9ZtEFfijlBdQ2dzBzwusce28+Ao9+EV76CX75NH4x/ia+sPt0rr94Pp++qBzvia8R33Y/kmzKbF8+Fa78Oi+UXsy7v/sMH3/rAv5ney2bDzSxeMo47rj2PBZOCS84F/jU7dtOSxBl4pRZVJYl+rx9R8rjlxsPsPtoK5+8YhGHjrfzr7/dypM7jvbYTgSuPGsan1lxOqVxl5XfepKmjjRfeOcS3n/hbDIfDUj7AZtqGkmmAypKoiQ9n8/fv5mdtS1curCKRNTFD5SPvGUBT2yv5fbHdqAKk8pifOfa83jT/P5vdpPtxf2NlMddFkzueXG9uuYkmw8e5/JF1V01DRdVpTnpnfhfdgW0cV8D5fEIi6YMfFFCU3jDGvgi4gKvAlcANcA64BpV3Zq1zSrgY2QC/0LgdlW9cKDXLdbAH3L7noO1n4LDm9Dq05HyKZmzgNWHM98LC98OGsBT34IjL0P5VDboQrYdjzFN6jmjIsnzbVM54FVy3vQSFgW7KKt/mUTQBkCHRmmffC4TZiymJeXR9OpfqEofIoLPJp3HE8E5HBt3BpvaJhC4CW5e1Mbi2FFSzbVMaN8LzUc43OJzQCZztHwxjx2fRtn0M3hsr8ebZyf4xzeUU5pu5J51tTx9JEo9lQQ4OAQsL6/l+smvMe3w/zBFj+JqmoPBBA5qFfGq06icOpcHdzu80DSOD77jEt5z8TngtfPq/kN855GXufzM05g/eRyPb97H25ctIVZSzju//WemB4f5+0Ueq990NlUz5nOMCt73X8+yq66VN82fxIqlU2lsS7O3vpWzZozjunPKETfK1mPwud9spanDY9GUcr60+kymVGR+Ga7bc4xjrSlWLJ0KZEL9e0/uwhHh+ovn8siWw+yvb+bGpS53/Wk339/QwNvOWcCZM8dztCXJe86fyYLJ3Rf8W7/nGJ+/fzPL5kzg39591qAfg22Hm4i5DvOqy3lky2Ge2F7L/3r7YipLomw92ITrCHOqyiiPdx+WO9LUQVk80mMZwKHj7RxvT3P61Apqmzr4zK828cT2OiKOcP3FczjclCTtBXzosnl9hgZVlRf2N1LblOSCOROYFB7POtDYTkfaZ15VGSLCnqOtPLurnjfNr2JieYxv/vFV9h9rY0JpjOsunsMZ0zKz0H61oYaHtxzmP//2HCKO8PzuY7x5YXX/U6p7aepIs37PMV7cf5zLFlXxhtNOfPaeHyhrXz7EebPHdzVqbSmPrQebOHfWeCJ5Du1mvx5wcn/d52G4A/8i4IuquiJ8/jkAVf2PrG3+C3hCVX8aPt8OXK6qh/p7XQv8ExAEsPmX8Pz3Ms+rF8GbPwMTTuvexk9nzv599WFSBzfR0lBHe2IyM6bPIDi8FW1vwFNhu85iky6gYv4FnFYZYe/2l5jdtpmZkUbwPbYwH3fqEhwRzvJepvzoSwg5PiNuDCbOg4oZdCQ7aD6wjWqtH/RbUXHx3Tjip3DVyyycdg5MXkIKl5q9rzHRq6UyeRhJt57QbuogRow0Tq96U0Q4rBOJlFdzvKWViKaJkSbheIzXZuKS7tq2jQQ4EZK+0OqUk6iYRE17jOb2zFnRC2ZUM23SeLbVtrH/cB3jpJ0JbpKE38JkaaREus+eTqnLccpp1HI8XEriUbwAUoGQ9EHEIa0wa2IZrUmfpK9MqYijqviBMrE0Skt7ktrjrXjpFFF8KuJCS9JHERzHQRHSAV3PZ00qI+K61LWkqGtJ44hQURonHSjgEIm41DWnCBDOmT2B3fXtNLSlmT2pnPaOJI0trZQ6PlHSOEGaRCxGWWkJ6sZo8RyOtikNKSEg895TKuKUJ6LsqmvF10zIBTikAiFAQFyi0QgtKaWiJEZTUkkGMG9yBTMmlPHY9no8FaaPL6XNgyMtaS5aMJkL5lax82g7bWmlNB5jwZQKHIGOVJID9a3U1DdxoKGV2qYOAg2DVeDcWRMYXxojFnEpT0SZWlkCAjUN7UwqTzChNAZAY7vHc7uPUZaIsrO2hf0N7biOwzmzJhAEyitHmmlLBUyvLOH0aePYe6ydNy2oZn51OTvrWnj6tWPsa2jnH954GqdNKsu8uQg761r4+bp9tCU9SmMRvMCnPOYyd1IZlyyYRPW4eOZkzWnnwOwBe+J+DXfgvw9Yqao3hc//AbhQVW/N2uZ3wFdU9anw+WPAZ1V1fa/Xuhm4GWD27Nlv2Lt378nUbPKw/1gb0yoTPbqTY60pDja2M6Es1nUGckvS4wu/2czB4+0snDyOD102r+dwVLKF1ppNJFoP4XqtMHkpVC2E+LjMeE6oNemxadsO3liyH2ncC23HSEbK2ZcspdWtZMEEl/JUXeYOYl4HuFGoPiPzoZ8wp+83oArtDXC8hnTDPn7+6NPU1R6iTeOk3BJuvHwp7W3NtHakmDpxPPf/5SUiyUYuWzqLxYuXciQ2i98/t4XWur1M1XounZJkarQd34niSZRILIETifPUAZ8/HowRlYBzJ7u8bW6CkgjUHm9h3Su7KQ+aqY62UzWuhMa2FF6qg3LXI/DSREsriJZWsK1BmFJdjZZVc++OBEumj+f9Z48j3XKUoO0YTsdxXjvSSHN7kpgjJFylNOYwozLGKweP09yewhGIuULSy/z/qAACvjrE4nGmTyinoUPZ15hi8rg4iyaXsf1wExEHplfGEVVeq2umI+UhKI4oMyoTeL5PY1uSkohkjpmkPSaVxWhuTxJxhLTnMaMyztRxscwvOlxisRJ8J8be42lq6lvw00mieMQdnwkxpapEiLsBrUmfhtYkgUJFwqUsFiHleQgBUQcSLrR2pPC8NOMTEWKOEgQ+yVSKtOfjEBCRgIgD6vu4BDgyNu4u9+qCm1j09yd31d3hDvy/AVb0CvzlqvqxrG1+D/xHr8D/jKpuyPWaYB2+OTGeH/DUzqNs2NvA8rkTuXRhz2m5+4+1sWFvA6vPnX5CY/RBoDz6yhHOnFHJ9F6X4dh9tJWWDo8zZ1QgIjS0prjh3nXEIw5/dfoUrr94Tp8/9xtaU1SWRPMekjh0vJ3bH93BBy6aw6Ip5Ty18yhV5XHiEYcHXjzIrIklvPf8mV3vs6uuhdkTS3MOMxxvT3Pv03uoKo9z8YJJYefZkx8oriP89Pl9fO7XLzO3qoyHP3Ep8UjuA+NBoOxvaMMRYXJFvM929S1Jdta2sHzuxBPa73vrW/nJc/u4Zvls5lSV8ejWI8ypKmNaRZz33PkkDa0dfH7VIpbPHs8L+45x719eIxGNsmzuJJbNn8x5syeRiMWyXlFBldaURzLt09Se4mBjGxv3NpL0PC6aO4mX9jfwyNbDbD/cxILqMu645jwmlEWJOkJJ1Mm6TIp2PW5LebQlPZSAG+9dz4FjbVx59lQ+v+p09hxt46Z7nyeZzvyimj2xlAtOm8BH3rqAslg0qyESjram+PofXuXpXccYXxrlPcsXct3lS/PeX9lsSMcYc0KCQLnz8Z1cvngyZ80cWedttKU8VKEsPjynCTV3pCmNRU54jP3w8Q5e3N/IiqVTun65Pb3zKLuOtvL2pVOYPK7v5IfhMNyBHyFz0PavgANkDtpeq6pbsra5EriV7oO231bV5QO9rgW+McacuGE901ZVPRG5FXiEzLTMe1R1i4jcEq5fA6wlE/Y7yUzLzH2aqjHGmILJ628mVV1LJtSzl63JeqzAR4e2NGOMMUNp1F0e2RhjzMmxwDfGmDHCAt8YY8YIC3xjjBkjLPCNMWaMsMA3xpgxomDXwxeROuBkL6ZTBRwddKvCsfpeH6vv9RnJ9Y3k2mB01Femqid1y7+CBf7rISLrT/ZMs1PB6nt9rL7XZyTXN5Jrg+Kvz4Z0jDFmjLDAN8aYMWK0Bv7dhS5gEFbf62P1vT4jub6RXBsUeX2jcgzfGGPMiRutHb4xxpgTZIFvjDFjxKgLfBFZKSLbRWSniNw2AuqZJSKPi8grIrJFRP4pXP5FETkgIi+G/60qYI17ROTlsI714bKJIvJHEdkR/juhAHUtzto/L4pIk4h8opD7TkTuEZFaEdmctazffSUinws/i9tFZEWB6vuaiGwTkU0icr+IjA+XzxGR9qz9uKbfFx7e+vr9eY6Q/fezrNr2iMiL4fJTuv8GyJKh+/yp6qj5j8wNWF4D5gEx4CVgSYFrmgacHz4eR+buYEuALwKfKvQ+C+vaA1T1WvZ/gdvCx7cBXx0BP9vDwGmF3HfAm4Hzgc2D7avw5/wSEAfmhp9NtwD1vR2IhI+/mlXfnOztCrj/cv48R8r+67X+P4EvFGL/DZAlQ/b5G20d/nJgp6ruUtUUcB+wupAFqeohVd0YPm4GXgFmFLKmPK0G7g0f3wu8q3ClAJlbaL6mqid79vWQUNU/A8d6Le5vX60G7lPVpKruJnPHtwFv7Tkc9anqH1TVC58+C8wczhoG0s/+68+I2H+dJHOj2r8FfjqcNfRngCwZss/faAv8GcD+rOc1jKBwFZE5wHnAc+GiW8M/s+8pxJBJFgX+ICIbROTmcNkUDW8yH/47uWDVZVxNz//RRsq+g/731Uj8PN4APJT1fK6IvCAifxKRSwtVFLl/niNt/10KHFHVHVnLCrL/emXJkH3+Rlvg57rN/IiYVyoi5cCvgE+oahPwXWA+cC5wiMyfioVysaqeD7wD+KiIvLmAtfQhIjHgKuAX4aKRtO8GMqI+jyLyecADfhwuOgTMVtXzgE8CPxGRigKU1t/Pc0TtP+AaejYdBdl/ObKk301zLBtw/422wK8BZmU9nwkcLFAtXUQkSuYH9GNV/TWAqh5RVV9VA+B7DPOfqgNR1YPhv7XA/WEtR0RkGkD4b22h6iPzi2ijqh6BkbXvQv3tqxHzeRSRDwLvBN6v4QBv+Kd+ffh4A5kx3kWnurYBfp4jaf9FgPcAP+tcVoj9lytLGMLP32gL/HXAQhGZG3aFVwMPFrKgcNzvB8ArqvqNrOXTsjZ7N7C599eeCiJSJiLjOh+TOcC3mcx++2C42QeBBwpRX6hHZzVS9l2W/vbVg8DVIhIXkbnAQuD5U12ciKwEPgtcpaptWcurRcQNH88L69tVgPr6+3mOiP0XehuwTVVrOhec6v3XX5YwlJ+/U3UEegiPZK8ic/T6NeDzI6CeS8j8GbUJeDH8bxXw/4CXw+UPAtMKVN88MkfyXwK2dO4zYBLwGLAj/HdigeorBeqByqxlBdt3ZH7xHALSZDqoGwfaV8Dnw8/iduAdBapvJ5mx3M7P35pw2/eGP/OXgI3AXxeovn5/niNh/4XLfwjc0mvbU7r/BsiSIfv82aUVjDFmjBhtQzrGGGNOkgW+McaMERb4xhgzRljgG2PMGGGBb4wxY4QFvjHGjBEW+MYYM0b8fzMVi7SqnNCyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf_PSD_normal = tf.cast(df_PSD_normal,float)\n",
    "tf_PSD_abnormal = tf.cast(df_PSD_abnormal.iloc[:,:-1],float)\n",
    "\n",
    "MIN,MAX = MinMaxNormalisation.getMinMax(tf_PSD_normal)\n",
    "tf_PSD_normal = MinMaxNormalisation.fun(tf_PSD_normal,MIN,MAX)\n",
    "tf_PSD_abnormal = MinMaxNormalisation.fun(tf_PSD_abnormal,MIN,MAX)\n",
    "\n",
    "encoded_normal = autoencoder.encoder(tf_PSD_normal,192)\n",
    "encoded_abnormal = autoencoder.encoder(tf_PSD_abnormal,192)\n",
    "\n",
    "y_vec_normal = [1]*len(encoded_normal)\n",
    "y_vec_abnormal = [2]*len(encoded_abnormal)\n",
    "plt.scatter(encoded_normal,y_vec_normal, color='green',alpha=0.1)\n",
    "plt.scatter(encoded_abnormal,y_vec_abnormal, color='red',alpha=0.1)\n",
    "plt.show\n",
    "\n",
    "#### Multiple plots\n",
    "ID_to_test = 340\n",
    "\n",
    "\n",
    "decoded_data = autoencoder.decoder(encoded_normal[ID_to_test])\n",
    "df_data = pd.DataFrame(decoded_data).transpose()\n",
    "\n",
    "df_data.plot()\n",
    "plt.plot(tf_PSD_normal[ID_to_test,:])\n",
    "plt.show\n",
    "\n",
    "#### Multiple plots\n",
    "\n",
    "\n",
    "decoded_data = autoencoder.decoder(encoded_abnormal[ID_to_test])\n",
    "df_data = pd.DataFrame(decoded_data).transpose()\n",
    "\n",
    "df_data.plot()\n",
    "plt.plot(tf_PSD_abnormal[ID_to_test,:])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45985646-0f7a-438f-9a04-f957c4c238fd",
   "metadata": {},
   "source": [
    "## Visualisation of the reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeca0deb-1d12-42bf-81ff-73c47c7d0bc9",
   "metadata": {},
   "source": [
    "- Utiliser le decoder \n",
    "\n",
    "- Sur chaque fréquence prendre la valeur moyenne et voir que tu peux mieux détecter qu'avec simplement un threshold.\n",
    "- Feature-based : MSE signal et recherche de threshold -> Pour comparer avec AE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293b291f-171a-4d8e-9286-ceb9e479b319",
   "metadata": {},
   "source": [
    "PSD / spectro : comparison entre les perf ventilateurs et vannes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63f10d8-f488-46c9-9de9-7e56bd079d28",
   "metadata": {},
   "source": [
    "## Implementation of the Mahlanobis distance insteand of MSE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
